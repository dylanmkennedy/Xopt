{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Time dependent Bayesian Optimization\n",
    "\n",
    "In this example we demonstrate time dependent optimization. In this case we are not\n",
    "only interested in finding an optimum point in input space, but also maintain the\n",
    "ideal point over time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# set values if testing\n",
    "import os\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "NUM_MC_SAMPLES = 1 if SMOKE_TEST else 128\n",
    "NUM_RESTARTS = 1 if SMOKE_TEST else 20\n",
    "\n",
    "from xopt.generators.bayesian.upper_confidence_bound import TDUpperConfidenceBoundGenerator\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.evaluator import Evaluator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Time dependent test problem\n",
    "Optimization is carried out over a single variable `x`. The test function is a simple\n",
    " quadratic, with a minimum location that drifts in the positive `x` direction over\n",
    " (real) time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables={'x': [-1.0, 1.0]} constraints={} objectives={'y': 'MINIMIZE'} constants={} linked_variables={}\n"
     ]
    },
    {
     "data": {
      "text/plain": "\n            Xopt\n________________________________\nVersion: 1.4.0+6.g2a95b36.dirty\nData size: 0\nConfig as YAML:\nxopt: {asynch: false, strict: false, dump_file: null, max_evaluations: null}\ngenerator:\n  name: time_dependent_upper_confidence_bound\n  optimization_options: {raw_samples: 20, num_restarts: 20, sequential: true, max_travel_distances: null,\n    use_turbo: false}\n  model: null\n  turbo_state: null\n  use_cuda: false\n  model_constructor:\n    name: standard\n    use_low_noise_prior: true\n    covar_modules: {}\n    mean_modules: {}\n    dtype: torch.float64\n    device: cpu\n  acquisition_options: {proximal_lengthscales: null, use_transformed_proximal_weights: true,\n    monte_carlo_samples: 128}\n  beta: 2.0\n  target_prediction_time: null\n  added_time: 1.0\nevaluator:\n  function: __main__.f\n  max_workers: 1\n  function_kwargs: {}\n  vectorized: false\nvocs:\n  variables:\n    x: [-1.0, 1.0]\n  constraints: {}\n  objectives: {y: MINIMIZE}\n  constants: {}\n  linked_variables: {}\n"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test evaluate function and vocs\n",
    "import time\n",
    "from xopt import Xopt\n",
    "\n",
    "start_time = time.time()\n",
    "def f(inputs):\n",
    "    x_ = inputs[\"x\"]\n",
    "    current_time = time.time()\n",
    "    t_ = current_time - start_time\n",
    "    y_ = 5*(x_ - t_*1e-2)**2\n",
    "    return {\"y\":y_, \"time\":current_time}\n",
    "\n",
    "variables = {\"x\":[-1,1]}\n",
    "objectives = {\"y\": \"MINIMIZE\"}\n",
    "\n",
    "vocs = VOCS(variables=variables, objectives=objectives)\n",
    "print(vocs)\n",
    "\n",
    "evaluator = Evaluator(function=f)\n",
    "generator = TDUpperConfidenceBoundGenerator(vocs=vocs)\n",
    "generator.added_time=1.0\n",
    "generator.beta = 2.0\n",
    "generator.acquisition_options.monte_carlo_samples = NUM_MC_SAMPLES\n",
    "generator.optimization_options.num_restarts = NUM_RESTARTS\n",
    "\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m warnings\u001B[38;5;241m.\u001B[39mcatch_warnings():\n\u001B[0;32m      7\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mfilterwarnings(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, category\u001B[38;5;241m=\u001B[39m\u001B[38;5;167;01mRuntimeWarning\u001B[39;00m)\n\u001B[1;32m----> 8\u001B[0m         \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(X\u001B[38;5;241m.\u001B[39mgenerator\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\base.py:219\u001B[0m, in \u001B[0;36mXopt.step\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;66;03m# generate samples and submit to evaluator\u001B[39;00m\n\u001B[0;32m    218\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_generate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m candidates\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 219\u001B[0m new_samples \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_generate\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    221\u001B[0m \u001B[38;5;66;03m# generator is done when it returns no new samples\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(new_samples) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\time_dependent.py:28\u001B[0m, in \u001B[0;36mTimeDependentBayesianGenerator.generate\u001B[1;34m(self, n_candidates)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate\u001B[39m(\u001B[38;5;28mself\u001B[39m, n_candidates: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_prediction_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madded_time\n\u001B[1;32m---> 28\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_prediction_time:\n\u001B[0;32m     31\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m     32\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtarget prediction time is in the past! Increase \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     33\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madded time for accurate results\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     34\u001B[0m             \u001B[38;5;167;01mRuntimeWarning\u001B[39;00m,\n\u001B[0;32m     35\u001B[0m         )\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:131\u001B[0m, in \u001B[0;36mBayesianGenerator.generate\u001B[1;34m(self, n_candidates)\u001B[0m\n\u001B[0;32m    128\u001B[0m bounds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_optimization_bounds()\n\u001B[0;32m    130\u001B[0m \u001B[38;5;66;03m# get acquisition function\u001B[39;00m\n\u001B[1;32m--> 131\u001B[0m acq_funct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_acquisition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;66;03m# get candidates\u001B[39;00m\n\u001B[0;32m    134\u001B[0m candidates \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimize_acqf(acq_funct, bounds, n_candidates)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\time_dependent.py:42\u001B[0m, in \u001B[0;36mTimeDependentBayesianGenerator.get_acquisition\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_acquisition\u001B[39m(\u001B[38;5;28mself\u001B[39m, model):\n\u001B[1;32m---> 42\u001B[0m     acq \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_acquisition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     44\u001B[0m     \u001B[38;5;66;03m# identify which column has the `time` attribute\u001B[39;00m\n\u001B[0;32m     45\u001B[0m     column \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:171\u001B[0m, in \u001B[0;36mBayesianGenerator.get_acquisition\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel cannot be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;66;03m# get base acquisition function\u001B[39;00m\n\u001B[1;32m--> 171\u001B[0m acq \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_acquisition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    173\u001B[0m \u001B[38;5;66;03m# add proximal biasing if requested\u001B[39;00m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39macquisition_options\u001B[38;5;241m.\u001B[39mproximal_lengthscales \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\upper_confidence_bound.py:19\u001B[0m, in \u001B[0;36mUpperConfidenceBoundGenerator._get_acquisition\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_acquisition\u001B[39m(\u001B[38;5;28mself\u001B[39m, model):\n\u001B[1;32m---> 19\u001B[0m     sampler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_sampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     qUCB \u001B[38;5;241m=\u001B[39m qUpperConfidenceBound(\n\u001B[0;32m     21\u001B[0m         model,\n\u001B[0;32m     22\u001B[0m         sampler\u001B[38;5;241m=\u001B[39msampler,\n\u001B[0;32m     23\u001B[0m         objective\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_objective(),\n\u001B[0;32m     24\u001B[0m         beta\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta,\n\u001B[0;32m     25\u001B[0m     )\n\u001B[0;32m     27\u001B[0m     cqUCB \u001B[38;5;241m=\u001B[39m ConstrainedMCAcquisitionFunction(\n\u001B[0;32m     28\u001B[0m         model,\n\u001B[0;32m     29\u001B[0m         qUCB,\n\u001B[0;32m     30\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_constraint_callables(),\n\u001B[0;32m     31\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:225\u001B[0m, in \u001B[0;36mBayesianGenerator._get_sampler\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_sampler\u001B[39m(\u001B[38;5;28mself\u001B[39m, model):\n\u001B[0;32m    223\u001B[0m     input_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_input_data(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata)\n\u001B[0;32m    224\u001B[0m     sampler \u001B[38;5;241m=\u001B[39m get_sampler(\n\u001B[1;32m--> 225\u001B[0m         \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposterior\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m    226\u001B[0m         sample_shape\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mSize([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39macquisition_options\u001B[38;5;241m.\u001B[39mmonte_carlo_samples]),\n\u001B[0;32m    227\u001B[0m     )\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m sampler\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\models\\gpytorch.py:653\u001B[0m, in \u001B[0;36mModelListGPyTorchModel.posterior\u001B[1;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001B[0m\n\u001B[0;32m    651\u001B[0m     mvn_gen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(output_indices, mvns)\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 653\u001B[0m     mvns \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtransformed_X\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    654\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m observation_noise \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    655\u001B[0m         mvnX \u001B[38;5;241m=\u001B[39m [(mvn, transformed_X[i]) \u001B[38;5;28;01mfor\u001B[39;00m i, mvn \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(mvns)]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\gpytorch\\models\\model_list.py:88\u001B[0m, in \u001B[0;36mIndependentModelList.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m     89\u001B[0m         model\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m model, args_ \u001B[38;5;129;01min\u001B[39;00m length_safe_zip(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels, _get_tensor_args(\u001B[38;5;241m*\u001B[39margs))\n\u001B[0;32m     90\u001B[0m     ]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\gpytorch\\models\\model_list.py:89\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m---> 89\u001B[0m         model\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m model, args_ \u001B[38;5;129;01min\u001B[39;00m length_safe_zip(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels, _get_tensor_args(\u001B[38;5;241m*\u001B[39margs))\n\u001B[0;32m     90\u001B[0m     ]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\gpytorch\\models\\exact_gp.py:312\u001B[0m, in \u001B[0;36mExactGP.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m         train_input \u001B[38;5;241m=\u001B[39m train_input\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m*\u001B[39mbatch_shape, \u001B[38;5;241m*\u001B[39mtrain_input\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:])\n\u001B[0;32m    311\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m*\u001B[39mbatch_shape, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:])\n\u001B[1;32m--> 312\u001B[0m     full_inputs\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    314\u001B[0m \u001B[38;5;66;03m# Get the joint distribution for training/test data\u001B[39;00m\n\u001B[0;32m    315\u001B[0m full_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(ExactGP, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39mfull_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "X.random_evaluate(5)\n",
    "\n",
    "for _ in range(20):\n",
    "    # note that in this example we can ignore warnings if computation time is greater\n",
    "    # than added time\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        X.step()\n",
    "        time.sleep(0.1)\n",
    "\n",
    "print(X.generator.generate(1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "          x         y          time  xopt_runtime  xopt_error\n1  0.735627  2.611637  1.684868e+09      0.000008       False\n2  0.552599  1.456348  1.684868e+09      0.000002       False\n3  0.865775  3.636933  1.684868e+09      0.000001       False\n4  0.316749  0.461607  1.684868e+09      0.000001       False\n5  0.196528  0.168587  1.684868e+09      0.000001       False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>time</th>\n      <th>xopt_runtime</th>\n      <th>xopt_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.735627</td>\n      <td>2.611637</td>\n      <td>1.684868e+09</td>\n      <td>0.000008</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.552599</td>\n      <td>1.456348</td>\n      <td>1.684868e+09</td>\n      <td>0.000002</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.865775</td>\n      <td>3.636933</td>\n      <td>1.684868e+09</td>\n      <td>0.000001</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.316749</td>\n      <td>0.461607</td>\n      <td>1.684868e+09</td>\n      <td>0.000001</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.196528</td>\n      <td>0.168587</td>\n      <td>1.684868e+09</td>\n      <td>0.000001</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 25\u001B[0m\n\u001B[0;32m     22\u001B[0m gt_vals \u001B[38;5;241m=\u001B[39m gt(pts)\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 25\u001B[0m     post \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposterior\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgp_pts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m     mean \u001B[38;5;241m=\u001B[39m post\u001B[38;5;241m.\u001B[39mmean\n\u001B[0;32m     28\u001B[0m     std \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msqrt(post\u001B[38;5;241m.\u001B[39mvariance)\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\models\\gpytorch.py:653\u001B[0m, in \u001B[0;36mModelListGPyTorchModel.posterior\u001B[1;34m(self, X, output_indices, observation_noise, posterior_transform, **kwargs)\u001B[0m\n\u001B[0;32m    651\u001B[0m     mvn_gen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(output_indices, mvns)\n\u001B[0;32m    652\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 653\u001B[0m     mvns \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtransformed_X\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    654\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m observation_noise \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[0;32m    655\u001B[0m         mvnX \u001B[38;5;241m=\u001B[39m [(mvn, transformed_X[i]) \u001B[38;5;28;01mfor\u001B[39;00m i, mvn \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(mvns)]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\gpytorch\\models\\model_list.py:88\u001B[0m, in \u001B[0;36mIndependentModelList.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m     89\u001B[0m         model\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m model, args_ \u001B[38;5;129;01min\u001B[39;00m length_safe_zip(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels, _get_tensor_args(\u001B[38;5;241m*\u001B[39margs))\n\u001B[0;32m     90\u001B[0m     ]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\gpytorch\\models\\model_list.py:89\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m---> 89\u001B[0m         model\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39margs_, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m model, args_ \u001B[38;5;129;01min\u001B[39;00m length_safe_zip(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodels, _get_tensor_args(\u001B[38;5;241m*\u001B[39margs))\n\u001B[0;32m     90\u001B[0m     ]\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\gpytorch\\models\\exact_gp.py:312\u001B[0m, in \u001B[0;36mExactGP.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    310\u001B[0m         train_input \u001B[38;5;241m=\u001B[39m train_input\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m*\u001B[39mbatch_shape, \u001B[38;5;241m*\u001B[39mtrain_input\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:])\n\u001B[0;32m    311\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mexpand(\u001B[38;5;241m*\u001B[39mbatch_shape, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:])\n\u001B[1;32m--> 312\u001B[0m     full_inputs\u001B[38;5;241m.\u001B[39mappend(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    314\u001B[0m \u001B[38;5;66;03m# Get the joint distribution for training/test data\u001B[39;00m\n\u001B[0;32m    315\u001B[0m full_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m(ExactGP, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39mfull_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# plot model\n",
    "import torch\n",
    "from matplotlib import pyplot as plt  # plot model predictions\n",
    "data = X.data\n",
    "\n",
    "xbounds = generator.vocs.bounds\n",
    "tbounds = [data[\"time\"].min(), data[\"time\"].max()]\n",
    "\n",
    "def gt(inpts):\n",
    "    return 5*(inpts[:,1] - (inpts[:,0] - start_time)*1e-2)**2\n",
    "\n",
    "model = X.generator.model\n",
    "n = 200\n",
    "t = torch.linspace(*tbounds, n, dtype=torch.double)\n",
    "x = torch.linspace(*xbounds.flatten(), n, dtype=torch.double)\n",
    "tt, xx = torch.meshgrid(t, x)\n",
    "pts = torch.hstack([ele.reshape(-1, 1) for ele in (tt, xx)]).double()\n",
    "\n",
    "#NOTE: the model inputs are such that t is the last dimension\n",
    "gp_pts = torch.flip(pts, dims=[-1])\n",
    "\n",
    "gt_vals = gt(pts)\n",
    "\n",
    "with torch.no_grad():\n",
    "    post = model.posterior(gp_pts)\n",
    "\n",
    "    mean = post.mean\n",
    "    std = torch.sqrt(post.variance)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"model mean\")\n",
    "    ax.set_xlabel(\"unix time\")\n",
    "    ax.set_ylabel(\"x\")\n",
    "    c = ax.pcolor(tt, xx, mean.reshape(n,n))\n",
    "    fig.colorbar(c)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.set_title(\"model uncertainty\")\n",
    "    ax2.set_xlabel(\"unix time\")\n",
    "    ax2.set_ylabel(\"x\")\n",
    "    c = ax2.pcolor(tt, xx, std.reshape(n,n))\n",
    "    fig2.colorbar(c)\n",
    "\n",
    "    ax.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(),\"oC1\")\n",
    "    ax2.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(),\"oC1\")\n",
    "\n",
    "    fig3, ax3 = plt.subplots()\n",
    "    ax3.set_title(\"ground truth value\")\n",
    "    ax3.set_xlabel(\"unix time\")\n",
    "    ax3.set_ylabel(\"x\")\n",
    "    c = ax3.pcolor(tt, xx, gt_vals.reshape(n,n))\n",
    "    fig3.colorbar(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(model.named_parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot the acquisition function\n",
    "# note that target time is only updated during the generate call\n",
    "target_time = generator.target_prediction_time\n",
    "print(target_time-start_time)\n",
    "my_acq_func = generator.get_acquisition(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    acq_pts = x.unsqueeze(-1).unsqueeze(-1)\n",
    "    full_acq = my_acq_func.acq_func(gp_pts.unsqueeze(1))\n",
    "    fixed_acq = my_acq_func(acq_pts)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    c = ax.pcolor(tt, xx, full_acq.reshape(n,n))\n",
    "    fig.colorbar(c)\n",
    "\n",
    "    fi2, ax2 = plt.subplots()\n",
    "    ax2.plot(x.flatten(), fixed_acq.flatten())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
