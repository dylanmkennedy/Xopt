{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Bayesian Optimization\n",
    "In this tutorial we demonstrate the use of Xopt to preform Bayesian Optimization on a\n",
    " simple test problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the test problem\n",
    "Here we define a simple optimization problem, where we attempt to minimize the sin\n",
    "function in the domian [0,2*pi]. Note that the function used to evaluate the\n",
    "objective function takes a dictionary as input and returns a dictionary as the output."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from xopt.vocs import VOCS\n",
    "import math\n",
    "\n",
    "# define variables and function objectives\n",
    "vocs = VOCS(\n",
    "    variables={\"x\": [0.0, 2.0]},\n",
    "    objectives={\"f\":\"MINIMIZE\"},\n",
    "    observables=[\"sx\",\"sy\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:41:28.453200600Z",
     "start_time": "2024-03-07T01:41:28.410745600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# define a test function to optimize\n",
    "import numpy as np\n",
    "\n",
    "def sin_function(input_dict):\n",
    "    return {\"sx\": input_dict[\"x\"]**2, \"sy\":(input_dict[\"x\"]-2.0)**2,\"f\":1.0}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:41:52.176063900Z",
     "start_time": "2024-03-07T01:41:52.144804200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Xopt objects\n",
    "Create the evaluator to evaluate our test function and create a generator that uses\n",
    "the Upper Confidence Bound acquisition function to perform Bayesian Optimization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate and evaluate initial points\n",
    "To begin optimization, we must generate some random initial data points. The first call\n",
    "to `X.step()` will generate and evaluate a number of randomly points specified by the\n",
    " generator. Note that if we add data to xopt before calling `X.step()` by assigning\n",
    " the data to `X.data`, calls to `X.step()` will ignore the random generation and\n",
    " proceed to generating points via Bayesian optimization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Do bayesian optimization steps\n",
    "To perform optimization we simply call `X.step()` in a loop. This allows us to do\n",
    "intermediate tasks in between optimization steps, such as examining the model and\n",
    "acquisition function at each step (as we demonstrate here)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rroussel\\AppData\\Local\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\botorch\\models\\utils\\assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([0.], dtype=torch.float64), std = tensor([0.], dtype=torch.float64)). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot specify objectives in VOCS and a custom objective for the generator",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 43\u001B[0m\n\u001B[0;32m     40\u001B[0m model \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mgenerator\u001B[38;5;241m.\u001B[39mtrain_model()\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# get acquisition function from generator\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m acq \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_acquisition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# calculate model posterior and acquisition function at each test point\u001B[39;00m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# NOTE: need to add a dimension to the input tensor for evaluating the\u001B[39;00m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# posterior and another for the acquisition function, see\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# https://botorch.org/docs/batching for details\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# NOTE: we use the `torch.no_grad()` environment to speed up computation by\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# skipping calculations for backpropagation\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:465\u001B[0m, in \u001B[0;36mBayesianGenerator.get_acquisition\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m    462\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel cannot be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    464\u001B[0m \u001B[38;5;66;03m# get base acquisition function\u001B[39;00m\n\u001B[1;32m--> 465\u001B[0m acq \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_acquisition\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    467\u001B[0m \u001B[38;5;66;03m# apply constraints if specified in vocs\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;66;03m# TODO: replace with direct constrainted acquisition function calls\u001B[39;00m\n\u001B[0;32m    469\u001B[0m \u001B[38;5;66;03m# see SampleReducingMCAcquisitionFunction in botorch for rationale\u001B[39;00m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocs\u001B[38;5;241m.\u001B[39mconstraints):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\upper_confidence_bound.py:55\u001B[0m, in \u001B[0;36mUpperConfidenceBoundGenerator._get_acquisition\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_acquisition\u001B[39m(\u001B[38;5;28mself\u001B[39m, model):\n\u001B[1;32m---> 55\u001B[0m     objective \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_objective\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_candidates \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(objective, CustomXoptObjective):\n\u001B[0;32m     57\u001B[0m         \u001B[38;5;66;03m# MC sampling for generating multiple candidate points\u001B[39;00m\n\u001B[0;32m     58\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sampler(model)\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:555\u001B[0m, in \u001B[0;36mBayesianGenerator._get_objective\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcustom_objective \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    554\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocs\u001B[38;5;241m.\u001B[39mn_objectives:\n\u001B[1;32m--> 555\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot specify objectives in VOCS and a custom objective for the generator\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    557\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcustom_objective\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: cannot specify objectives in VOCS and a custom objective for the generator"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xopt.evaluator import Evaluator\n",
    "from xopt.generators.bayesian import UpperConfidenceBoundGenerator\n",
    "from xopt import Xopt\n",
    "from xopt.generators.bayesian.objectives import CustomXoptObjective\n",
    "from torch import Tensor\n",
    "from typing import Optional\n",
    "\n",
    "class MyObjective(CustomXoptObjective):\n",
    "    def forward(self, samples: Tensor, X: Optional[Tensor] = None) -> Tensor:\n",
    "        return -torch.sqrt(samples[\n",
    "            ..., self.vocs.output_names.index(\"sx\")\n",
    "        ]**2 + samples[\n",
    "            ..., self.vocs.output_names.index(\"sy\")\n",
    "        ]**2)\n",
    "    \n",
    "class MyObjective2(CustomXoptObjective):\n",
    "    def forward(self, samples: Tensor, X: Optional[Tensor] = None) -> Tensor:\n",
    "        return torch.max(samples[\n",
    "            ..., self.vocs.output_names.index(\"sx\")\n",
    "        ], samples[\n",
    "            ..., self.vocs.output_names.index(\"sy\")\n",
    "        ])\n",
    "    \n",
    "evaluator = Evaluator(function=sin_function)\n",
    "generator = UpperConfidenceBoundGenerator(vocs=vocs, custom_objective=MyObjective2(vocs))\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)\n",
    "\n",
    "X.random_evaluate(10)\n",
    "\n",
    "n_steps = 5\n",
    "\n",
    "# test points for plotting\n",
    "test_x = torch.linspace(*X.vocs.bounds.flatten(), 50).double()\n",
    "\n",
    "for i in range(n_steps):\n",
    "    # get the Gaussian process model from the generator\n",
    "    model = X.generator.train_model()\n",
    "\n",
    "    # get acquisition function from generator\n",
    "    acq = X.generator.get_acquisition(model)\n",
    "\n",
    "    # calculate model posterior and acquisition function at each test point\n",
    "    # NOTE: need to add a dimension to the input tensor for evaluating the\n",
    "    # posterior and another for the acquisition function, see\n",
    "    # https://botorch.org/docs/batching for details\n",
    "    # NOTE: we use the `torch.no_grad()` environment to speed up computation by\n",
    "    # skipping calculations for backpropagation\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(test_x.unsqueeze(1))\n",
    "        acq_val = acq(test_x.reshape(-1,1, 1))\n",
    "\n",
    "    # get mean function and confidence regions\n",
    "    mean = posterior.mean\n",
    "    l,u = posterior.mvn.confidence_region()\n",
    "\n",
    "    # plot model and acquisition function\n",
    "    fig,ax = plt.subplots(2, 1, sharex=\"all\")\n",
    "\n",
    "    # plot model posterior\n",
    "    ax[0].plot(test_x, mean, label=\"Posterior mean\")\n",
    "    #ax[0].fill_between(test_x, l, u, alpha=0.25, label=\"Posterior confidence region\")\n",
    "\n",
    "    # add data to model plot\n",
    "    ax[0].plot(X.data[\"x\"],X.data[X.vocs.output_names],\"C1o\", label=\"Training data\")\n",
    "\n",
    "    # plot true function\n",
    "\n",
    "    # add legend\n",
    "    ax[0].legend()\n",
    "\n",
    "    # plot acquisition function\n",
    "    ax[1].plot(test_x, acq_val.flatten())\n",
    "\n",
    "    ax[0].set_ylabel(\"f\")\n",
    "    ax[1].set_ylabel(r\"$\\alpha(x)$\")\n",
    "    ax[1].set_xlabel(\"x\")\n",
    "\n",
    "    # do the optimization step\n",
    "    X.step()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:41:54.782413Z",
     "start_time": "2024-03-07T01:41:54.463790900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "           x        sx        sy  xopt_runtime  xopt_error\n0   1.496820  2.240471  0.253190  4.500000e-06       False\n1   0.072993  0.005328  3.713355  1.400000e-06       False\n2   1.198714  1.436916  0.642059  8.000000e-07       False\n3   0.956350  0.914605  1.089206  8.000000e-07       False\n4   0.768281  0.590256  1.517132  7.000000e-07       False\n5   1.850906  3.425852  0.022229  9.000000e-07       False\n6   0.029408  0.000865  3.883231  7.000000e-07       False\n7   0.467056  0.218141  2.349917  8.000000e-07       False\n8   0.143156  0.020494  3.447868  7.000000e-07       False\n9   0.732890  0.537128  1.605567  8.000000e-07       False\n10  0.000000  0.000000  4.000000  4.500000e-06       False\n11  0.000000  0.000000  4.000000  6.900000e-06       False\n12  0.000000  0.000000  4.000000  5.300000e-06       False\n13  0.000000  0.000000  4.000000  7.000000e-06       False\n14  0.000000  0.000000  4.000000  4.300000e-06       False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>sx</th>\n      <th>sy</th>\n      <th>xopt_runtime</th>\n      <th>xopt_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.496820</td>\n      <td>2.240471</td>\n      <td>0.253190</td>\n      <td>4.500000e-06</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.072993</td>\n      <td>0.005328</td>\n      <td>3.713355</td>\n      <td>1.400000e-06</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.198714</td>\n      <td>1.436916</td>\n      <td>0.642059</td>\n      <td>8.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.956350</td>\n      <td>0.914605</td>\n      <td>1.089206</td>\n      <td>8.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.768281</td>\n      <td>0.590256</td>\n      <td>1.517132</td>\n      <td>7.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.850906</td>\n      <td>3.425852</td>\n      <td>0.022229</td>\n      <td>9.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.029408</td>\n      <td>0.000865</td>\n      <td>3.883231</td>\n      <td>7.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.467056</td>\n      <td>0.218141</td>\n      <td>2.349917</td>\n      <td>8.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.143156</td>\n      <td>0.020494</td>\n      <td>3.447868</td>\n      <td>7.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.732890</td>\n      <td>0.537128</td>\n      <td>1.605567</td>\n      <td>8.000000e-07</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>4.500000e-06</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>6.900000e-06</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>5.300000e-06</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>7.000000e-06</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>4.300000e-06</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access the collected data\n",
    "X.data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:40:58.190669900Z",
     "start_time": "2024-03-07T01:40:58.146152300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting the optimization result\n",
    "To get the best point (without evaluating it) we ask the generator to\n",
    "predict the optimum based on the posterior mean."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "     x\n0  0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.generator.get_optimum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:40:58.299178100Z",
     "start_time": "2024-03-07T01:40:58.175061300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Customizing optimization\n",
    "Each generator has a set of options that can be modified to effect optimization behavior"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rroussel\\AppData\\Local\\Temp\\1\\ipykernel_23624\\2160990163.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.4/migration/\n",
      "  X.generator.dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'model': ModelListGP(\n   (models): ModuleList(\n     (0-1): 2 x SingleTaskGP(\n       (likelihood): GaussianLikelihood(\n         (noise_covar): HomoskedasticNoise(\n           (noise_prior): GammaPrior()\n           (raw_noise_constraint): GreaterThan(1.000E-04)\n         )\n       )\n       (mean_module): ConstantMean()\n       (covar_module): ScaleKernel(\n         (base_kernel): MaternKernel(\n           (lengthscale_prior): GammaPrior()\n           (raw_lengthscale_constraint): Positive()\n         )\n         (outputscale_prior): GammaPrior()\n         (raw_outputscale_constraint): Positive()\n       )\n       (outcome_transform): Standardize()\n       (input_transform): Normalize()\n     )\n   )\n   (likelihood): LikelihoodList(\n     (likelihoods): ModuleList(\n       (0-1): 2 x GaussianLikelihood(\n         (noise_covar): HomoskedasticNoise(\n           (noise_prior): GammaPrior()\n           (raw_noise_constraint): GreaterThan(1.000E-04)\n         )\n       )\n     )\n   )\n ),\n 'n_monte_carlo_samples': 128,\n 'turbo_controller': None,\n 'use_cuda': False,\n 'gp_constructor': {'name': 'standard',\n  'use_low_noise_prior': True,\n  'covar_modules': {},\n  'mean_modules': {},\n  'trainable_mean_keys': [],\n  'transform_inputs': True},\n 'numerical_optimizer': {'name': 'LBFGS',\n  'n_restarts': 20,\n  'max_iter': 2000,\n  'max_time': None},\n 'max_travel_distances': None,\n 'fixed_features': None,\n 'computation_time':    training  acquisition_optimization\n 0  0.254387                  0.043844\n 1  0.260278                  0.058823\n 2  0.279125                  0.066495\n 3  0.199188                  0.050067\n 4  0.205320                  0.040790,\n 'log_transform_acquisition_function': False,\n 'custom_objective': MyObjective2(),\n 'n_interpolate_points': None,\n 'n_candidates': 1,\n 'beta': 2.0}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.generator.dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:40:58.299178100Z",
     "start_time": "2024-03-07T01:40:58.230544200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-07T01:40:58.299178100Z",
     "start_time": "2024-03-07T01:40:58.246167500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
