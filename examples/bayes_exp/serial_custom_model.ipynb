{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9be9bf-b3c5-468d-84f6-c7b8cf25806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import botorch\n",
    "\n",
    "from xopt.bayesian_exploration import bayesian_exploration\n",
    "from xopt.bayesian.models.nan_enabled import NanEnabledModelListGP\n",
    "\n",
    "from botorch.models import SingleTaskGP, ModelListGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "\n",
    "\n",
    "# test function\n",
    "from xopt.evaluators import test_TNK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b14413-2736-4f26-a308-611a9c10b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'TNK_test', 'description': 'Constrainted test function TNK. See Table V in https://www.iitk.ac.in/kangal/Deb_NSGA-II.pdf', 'simulation': 'test_TNK', 'variables': {'x1': [0, 3.14159], 'x2': [0, 3.14159]}, 'objectives': {'y1': None}, 'constraints': {'c1': ['GREATER_THAN', 0], 'c2': ['LESS_THAN', 0.5]}, 'constants': {'a': 'dummy_constant'}, 'linked_variables': {'x9': 'x1'}}\n",
      "No executor given. Running in serial mode.\n",
      "tensor([[1.5268, 0.0000]], dtype=torch.float64)\n",
      "tensor([[1.1159, 0.6873]], dtype=torch.float64)\n",
      "tensor([[0.4283, 0.0000]], dtype=torch.float64)\n",
      "tensor([[0.0000, 0.4852]], dtype=torch.float64)\n",
      "tensor([[0.3159, 0.9192]], dtype=torch.float64)\n",
      "tensor([[0.3629, 1.0217]], dtype=torch.float64)\n",
      "tensor([[0.7131, 1.0579]], dtype=torch.float64)\n",
      "tensor([[0.9858, 0.4335]], dtype=torch.float64)\n",
      "tensor([[0.2205, 1.0732]], dtype=torch.float64)\n",
      "tensor([[0.0483, 0.9995]], dtype=torch.float64)\n",
      "tensor([[0.0694, 1.0404]], dtype=torch.float64)\n",
      "tensor([[1.0958, 0.2503]], dtype=torch.float64)\n",
      "tensor([[1.0416, 0.1130]], dtype=torch.float64)\n",
      "tensor([[0.9272, 1.0209]], dtype=torch.float64)\n",
      "tensor([[0.4482, 1.1698]], dtype=torch.float64)\n",
      "tensor([[0.7117, 0.8183]], dtype=torch.float64)\n",
      "tensor([[1.1765, 0.6082]], dtype=torch.float64)\n",
      "tensor([[1.0392, 0.0732]], dtype=torch.float64)\n",
      "tensor([[0.6350, 1.1720]], dtype=torch.float64)\n",
      "tensor([[0.0720, 1.0478]], dtype=torch.float64)\n",
      "tensor([[0.5479, 0.9099]], dtype=torch.float64)\n",
      "tensor([[0.9964, 0.9786]], dtype=torch.float64)\n",
      "tensor([[0.3165, 1.1639]], dtype=torch.float64)\n",
      "tensor([[0.8414, 0.6533]], dtype=torch.float64)\n",
      "tensor([[1.1864, 0.4640]], dtype=torch.float64)\n",
      "tensor([[0.4278, 0.9460]], dtype=torch.float64)\n",
      "tensor([[0.4309, 0.9500]], dtype=torch.float64)\n",
      "tensor([[0.0081, 0.0000]], dtype=torch.float64)\n",
      "tensor([[1.0383, 0.0662]], dtype=torch.float64)\n",
      "tensor([[0.2287, 0.9792]], dtype=torch.float64)\n",
      "tensor([[0.2066, 0.9533]], dtype=torch.float64)\n",
      "tensor([[0.0613, 1.0399]], dtype=torch.float64)\n",
      "tensor([[0.7849, 1.1305]], dtype=torch.float64)\n",
      "tensor([[0.8252, 0.6188]], dtype=torch.float64)\n",
      "tensor([[1.0876, 0.8660]], dtype=torch.float64)\n",
      "tensor([[0.3078, 1.1662]], dtype=torch.float64)\n",
      "tensor([[0.8023, 0.5837]], dtype=torch.float64)\n",
      "tensor([[1.1873, 0.4182]], dtype=torch.float64)\n",
      "tensor([[0.1971, 0.9442]], dtype=torch.float64)\n",
      "tensor([[1.0385, 0.0619]], dtype=torch.float64)\n",
      "tensor([[0.6098, 1.1853]], dtype=torch.float64)\n",
      "tensor([[0.5516, 0.8469]], dtype=torch.float64)\n",
      "tensor([[0.5482, 0.8031]], dtype=torch.float64)\n",
      "tensor([[0.9619, 1.0203]], dtype=torch.float64)\n",
      "tensor([[0.2702, 1.1566]], dtype=torch.float64)\n",
      "tensor([[1.1497, 0.7479]], dtype=torch.float64)\n",
      "tensor([[1.0386, 0.0592]], dtype=torch.float64)\n",
      "tensor([[0.7929, 0.5654]], dtype=torch.float64)\n",
      "tensor([[0.0591, 1.0403]], dtype=torch.float64)\n",
      "tensor([[1.1803, 0.3632]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Example where we must use a custom botorch model to make predictions. \n",
    "    We modify the test_TNK function with a wrapper to return Nan values for the y1 objective if one of the constraints are not satisfied.\n",
    "    To accomidate this we define a ModelListGP model as a custom model to remove Nan values from the training data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# define a new test function that returns nans for y1 if c1 is not valid\n",
    "def nan_test_TNK(x):\n",
    "    outputs = test_TNK.evaluate_TNK(x)\n",
    "    if outputs['c1'] < 0:\n",
    "        outputs['y1'] = np.nan\n",
    "        \n",
    "    return outputs\n",
    "\n",
    "class ModelCreationError(Exception):\n",
    "    pass\n",
    "    \n",
    "#function that creates a model that can account for nans\n",
    "def create_custom_model(train_x, train_outputs, input_transform):\n",
    "    n_outputs = train_outputs.shape[-1]\n",
    "    \n",
    "    # check if there are any nans\n",
    "    #has_nans = torch.any(torch.isnan(train_outputs))\n",
    "    has_nans = True\n",
    "    \n",
    "    if has_nans:\n",
    "        gp_models = []\n",
    "\n",
    "        for ii in range(n_outputs):\n",
    "            output = train_outputs[:, ii].flatten()\n",
    "\n",
    "            nan_state = torch.isnan(output)\n",
    "            not_nan_idx = torch.nonzero(~nan_state).flatten()\n",
    "\n",
    "            # remove elements that have nan values\n",
    "            temp_train_x = train_x[not_nan_idx]\n",
    "            temp_train_y = output[not_nan_idx].reshape(-1,1)\n",
    "\n",
    "            if len(temp_train_y) == 0:\n",
    "                print(train_outputs)\n",
    "                raise ModelCreationError('No valid measurements passed to model')\n",
    "\n",
    "            # create single task model and add to list\n",
    "            submodel = SingleTaskGP(temp_train_x, temp_train_y,\n",
    "                                    input_transform = input_transform)\n",
    "\n",
    "            mll = ExactMarginalLogLikelihood(submodel.likelihood, submodel)\n",
    "            fit_gpytorch_model(mll)\n",
    "\n",
    "            gp_models.append(submodel)\n",
    "\n",
    "        model = ModelListGP(*gp_models)\n",
    "        model.last_x = train_x[-1]\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        model = SingleTaskGP(train_x, train_outputs, input_transform = input_transform)\n",
    "        \n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_model(mll)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "\n",
    "\n",
    "# Get VOCS\n",
    "VOCS = test_TNK.VOCS\n",
    "VOCS['objectives'] = {'y1' : None}\n",
    "\n",
    "# add reference point\n",
    "ref = torch.tensor((1.4, 1.4))\n",
    "\n",
    "print(VOCS)\n",
    "# Get evaluate function\n",
    "EVALUATE = nan_test_TNK\n",
    "\n",
    "# Run\n",
    "init_x = torch.tensor([[0.9, 0.9], [0.6, 0.6]])\n",
    "train_x, train_y, train_c = bayesian_exploration(VOCS, EVALUATE,\n",
    "                                                 custom_model = NanEnabledModelListGP,\n",
    "                                                 n_initial_samples=5,\n",
    "                                                 mc_samples=128, initial_x=None,\n",
    "                                                 use_gpu=False,\n",
    "                                                 n_steps=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7b9312-17fe-438c-8120-c0fc458b6a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train_x[:, 0], train_x[:, 1],'.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9540a37-a0e8-4eff-a5ff-f11c9e68b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9155],\n",
      "        [3.0208],\n",
      "        [1.8412],\n",
      "        [2.9763],\n",
      "        [0.1623],\n",
      "        [1.5268],\n",
      "        [1.1159],\n",
      "        [   nan],\n",
      "        [   nan],\n",
      "        [   nan],\n",
      "        [0.3629],\n",
      "        [0.7131],\n",
      "        [0.9858],\n",
      "        [0.2205],\n",
      "        [   nan],\n",
      "        [0.0694],\n",
      "        [1.0958],\n",
      "        [1.0416],\n",
      "        [0.9272],\n",
      "        [0.4482],\n",
      "        [0.7117],\n",
      "        [1.1765],\n",
      "        [1.0392],\n",
      "        [0.6350],\n",
      "        [0.0720],\n",
      "        [0.5479],\n",
      "        [0.9964],\n",
      "        [0.3165],\n",
      "        [0.8414],\n",
      "        [1.1864],\n",
      "        [   nan],\n",
      "        [0.4309],\n",
      "        [   nan],\n",
      "        [1.0383],\n",
      "        [0.2287],\n",
      "        [0.2066],\n",
      "        [0.0613],\n",
      "        [0.7849],\n",
      "        [0.8252],\n",
      "        [1.0876],\n",
      "        [0.3078],\n",
      "        [0.8023],\n",
      "        [1.1873],\n",
      "        [0.1971],\n",
      "        [1.0385],\n",
      "        [0.6098],\n",
      "        [0.5516],\n",
      "        [0.5482],\n",
      "        [0.9619],\n",
      "        [0.2702],\n",
      "        [1.1497],\n",
      "        [1.0386],\n",
      "        [0.7929],\n",
      "        [0.0591],\n",
      "        [1.1803]], dtype=torch.float64)\n",
      "tensor([[ 3.8731e+00,  2.3410e+00],\n",
      "        [ 1.0049e+01,  7.1895e+00],\n",
      "        [ 5.5776e+00,  3.5227e+00],\n",
      "        [ 1.0942e+01,  7.6686e+00],\n",
      "        [ 8.7164e+00,  6.9978e+00],\n",
      "        [ 1.2310e+00,  1.3042e+00],\n",
      "        [ 8.0054e-01,  4.1438e-01],\n",
      "        [-9.1659e-01,  2.5515e-01],\n",
      "        [-8.6458e-01,  2.5022e-01],\n",
      "        [-1.1033e-01,  2.0965e-01],\n",
      "        [ 1.0750e-01,  2.9095e-01],\n",
      "        [ 7.2741e-01,  3.5663e-01],\n",
      "        [ 6.5592e-02,  2.4043e-01],\n",
      "        [ 2.9994e-01,  4.0674e-01],\n",
      "        [-7.0346e-02,  4.5350e-01],\n",
      "        [ 3.8771e-02,  4.7746e-01],\n",
      "        [ 3.5335e-01,  4.1732e-01],\n",
      "        [ 1.1343e-01,  4.4306e-01],\n",
      "        [ 8.3005e-01,  4.5383e-01],\n",
      "        [ 4.7834e-01,  4.5130e-01],\n",
      "        [ 1.3202e-01,  1.4616e-01],\n",
      "        [ 7.3223e-01,  4.6934e-01],\n",
      "        [ 4.2198e-02,  4.7293e-01],\n",
      "        [ 7.8579e-01,  4.6981e-01],\n",
      "        [ 5.7427e-02,  4.8327e-01],\n",
      "        [ 2.0109e-01,  1.7033e-01],\n",
      "        [ 8.5153e-01,  4.7549e-01],\n",
      "        [ 4.9950e-01,  4.7438e-01],\n",
      "        [ 1.7660e-01,  1.4005e-01],\n",
      "        [ 5.2780e-01,  4.7239e-01],\n",
      "        [-9.3839e-03,  2.0409e-01],\n",
      "        [ 1.8707e-03,  2.0731e-01],\n",
      "        [-1.0999e+00,  4.9200e-01],\n",
      "        [ 3.0007e-02,  4.7794e-01],\n",
      "        [ 9.7398e-02,  3.0323e-01],\n",
      "        [ 4.7688e-02,  2.9151e-01],\n",
      "        [ 2.6271e-02,  4.8388e-01],\n",
      "        [ 9.9004e-01,  4.7869e-01],\n",
      "        [ 1.2830e-01,  1.1985e-01],\n",
      "        [ 9.5621e-01,  4.7920e-01],\n",
      "        [ 5.0998e-01,  4.8082e-01],\n",
      "        [ 6.4669e-02,  9.8388e-02],\n",
      "        [ 5.1972e-01,  4.7910e-01],\n",
      "        [ 2.9259e-02,  2.8909e-01],\n",
      "        [ 2.4332e-02,  4.8197e-01],\n",
      "        [ 7.5186e-01,  4.8169e-01],\n",
      "        [ 1.1968e-01,  1.2298e-01],\n",
      "        [ 4.4269e-02,  9.4200e-02],\n",
      "        [ 8.7730e-01,  4.8413e-01],\n",
      "        [ 4.9688e-01,  4.8386e-01],\n",
      "        [ 9.7927e-01,  4.8357e-01],\n",
      "        [ 2.0915e-02,  4.8441e-01],\n",
      "        [ 3.6866e-02,  9.0095e-02],\n",
      "        [ 2.4093e-02,  4.8628e-01],\n",
      "        [ 5.1852e-01,  4.8147e-01]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_y)\n",
    "print(train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e3e48-fa51-4407-8cff-173f1b06e10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopt",
   "language": "python",
   "name": "xopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
