{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic-based executors\n",
    "The [PEP-3184](https://peps.python.org/pep-3148/) executor standard allows us to create an interface for executor objects and provide intelligent context for their execution. Pydantic validators allow the dynamic validation of executor initialization and execution based on signature inspection.\n",
    "\n",
    "Before you start, make sure you're using Pydantic >= 1.9.0. 1.8 has all sorts of bugs with json encoder propagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import contextlib\n",
    "import copy\n",
    "import inspect\n",
    "import logging\n",
    "from concurrent.futures import Future, ThreadPoolExecutor\n",
    "from importlib import import_module\n",
    "from typing import Any, Callable, Dict, Generic, Iterable, Optional, TypeVar\n",
    "from types import FunctionType\n",
    "from pydantic import BaseModel, Field, root_validator, validate_arguments, validator, ValidationError\n",
    "from pydantic.generics import GenericModel\n",
    "\n",
    "logger = logging.getLogger(\"__name__\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERICS\n",
    "\n",
    "Because the executor classes take many forms, we'll be making use of Pydantic's generic class composition for executor type interpolation. We are able to do this by creating a placeholder TypeVar. Here, this is names ObjType, because the executor classes make use of a generalizable loading approach that could be extented to objects generally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjType = TypeVar(\"ObjType\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Encoders\n",
    "\n",
    "Pydantic does not propogate JSON encoders to child classes, so we'll define a set of common encoders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_ENCODERS = {\n",
    "    FunctionType: lambda x: f\"{x.__module__}:{x.__name__}\",\n",
    "    Callable: lambda x: f\"{x.__module__}:{type(x).__name__}\", # for encoding functions\n",
    "    type: lambda x: f\"{x.__module__}:{x.__name__}\", # for encoding a type\n",
    "    ObjType: lambda x: f\"{x.__module__}:{x.__class__.__name__}\", # for encoding instances of the ObjType}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function for validating kwargs against a signature\n",
    "\n",
    "Central to generalizablity between executors is the ability to validate kwargs provided against the executor class. Below we define a utility using pydantic's validate_arguments decorator and the inspect module. At present, this method is only configured to handle kwargs (which will cover most cases), but could be extended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@validate_arguments(config={\"arbitrary_types_allowed\": True})\n",
    "def validate_and_compose_kwargs(signature: inspect.Signature, kwargs: Dict[str, Any]):\n",
    "    required_kwargs = [\n",
    "        kwarg.name\n",
    "        for kwarg in signature.parameters.values()\n",
    "        if (kwarg.POSITIONAL_OR_KEYWORD or kwarg.KEYWORD_ONLY)\n",
    "        and kwarg.default is inspect.Parameter.empty\n",
    "    ]\n",
    "\n",
    "    if any([required_kwarg not in kwargs.keys() for required_kwarg in kwargs.keys()]):\n",
    "        raise ValueError(\n",
    "            \"All required kwargs not provided: %s\", \", \".join(required_kwargs)\n",
    "        )\n",
    "\n",
    "    # check (kwarg.VAR_KEYWORD and kwarg.default is inspect.Parameter.empty) is not empty **kwargs\n",
    "    sig_kwargs = {\n",
    "        kwarg.name: kwarg.default\n",
    "        for kwarg in signature.parameters.values()\n",
    "        if (kwarg.POSITIONAL_OR_KEYWORD or kwarg.KEYWORD_ONLY)\n",
    "        and not kwarg.kind == inspect.Parameter.VAR_KEYWORD\n",
    "    }\n",
    "\n",
    "    # validate kwargs\n",
    "    if any([kwarg not in sig_kwargs.keys() for kwarg in kwargs.keys()]):\n",
    "        raise ValueError(\n",
    "            \"Kwargs must be members of function signature. Accepted kwargs are: %s, Provided: %s\",\n",
    "            \", \".join(sig_kwargs.keys()),\n",
    "            \", \".join(kwargs.keys()),\n",
    "        )\n",
    "\n",
    "    sig_kwargs.update(kwargs)\n",
    "\n",
    "    return sig_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing callables as Pydantic models\n",
    "Representing callables as pydantic models allows us to take advantage of both pydantic serialization to json and pydantic's validation hooks for the kwarg validation upon creation, with possibility of delaying load. Here `CallableModel`, we can provide initialization kwargs for a to-be-instantiated-later object and reap the benefit of additional kwarg validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallableModel(BaseModel):\n",
    "    callable: Callable\n",
    "    kwargs: dict\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "        json_encoders = JSON_ENCODERS\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_all(cls, values):\n",
    "        fn = values.pop(\"callable\")\n",
    "\n",
    "        if not isinstance(\n",
    "            fn,\n",
    "            (\n",
    "                str,\n",
    "                Callable,\n",
    "            ),\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"Callable must be object or a string. Provided %s\", type(fn)\n",
    "            )\n",
    "\n",
    "        # parse string to callable\n",
    "        if isinstance(fn, (str,)):\n",
    "\n",
    "            # for function loading\n",
    "            module_name, fn_name = fn.rsplit(\":\", 1)\n",
    "            fn = getattr(import_module(module_name), fn_name)\n",
    "\n",
    "        sig = inspect.signature(fn)\n",
    "\n",
    "        # for reloading:\n",
    "        if values.get(\"kwargs\") is not None:\n",
    "            values = values[\"kwargs\"]\n",
    "\n",
    "        kwargs = validate_and_compose_kwargs(sig, values)\n",
    "\n",
    "        return {\"callable\": fn, \"kwargs\": kwargs}\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        return self.callable(**{**self.kwargs, **kwargs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the callables on example function and class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(x: int, y: int = 5):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "class TestClass:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fn = CallableModel(callable=test_function, x=1, y=3)\n",
    "fn(y=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callable': <function __main__.test_function(x: int, y: int = 5)>,\n",
       " 'kwargs': {'x': 1, 'y': 3}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict rep\n",
    "fn_dict = fn.dict()\n",
    "fn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from dict\n",
    "fn_from_dict = CallableModel(**fn.dict()) \n",
    "fn_from_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"callable\": \"__main__:test_function\", \"kwargs\": {\"x\": 1, \"y\": 3}}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json representation\n",
    "fn.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callable from json\n",
    "fn_from_json = CallableModel.parse_raw(fn.json())\n",
    "fn_from_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class kwargs passed after\n",
    "parameterized_class = CallableModel(callable=TestClass, x=1, y=3)\n",
    "test_class_obj = parameterized_class()\n",
    "assert isinstance(test_class_obj, (TestClass,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callable': __main__.TestClass, 'kwargs': {'x': 1, 'y': 3}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict rep\n",
    "parameterized_class_dict = parameterized_class.dict()\n",
    "parameterized_class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CallableModel(callable=<class '__main__.TestClass'>, kwargs={'x': 1, 'y': 3})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dict\n",
    "parameterized_class_from_dict = CallableModel(**parameterized_class_dict)\n",
    "parameterized_class_from_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterized_class_from_dict_obj = parameterized_class_from_dict()\n",
    "assert isinstance(parameterized_class_from_dict_obj, (TestClass,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"callable\": \"__main__:TestClass\", \"kwargs\": {\"x\": 1, \"y\": 3}}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#json \n",
    "parameterized_class_json = parameterized_class.json()\n",
    "parameterized_class_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterized_class_from_json = CallableModel.parse_raw(parameterized_class_json)\n",
    "test_class_obj = parameterized_class_from_json()\n",
    "assert isinstance(test_class_obj, (TestClass,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the callables to construct a dynamic object loader. The generic type allows us to use this same method for any executor. The syntax: `ObjLoader[ThreadPoolExecutor]` composes a new class entirely, this one specific to the `ThreadPoolExecutor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ObjLoader(\n",
    "    GenericModel,\n",
    "    Generic[ObjType],\n",
    "    arbitrary_types_allowed=True,\n",
    "    json_encoders=JSON_ENCODERS,\n",
    "):\n",
    "    object: Optional[ObjType]\n",
    "    loader: CallableModel = None\n",
    "    object_type: Optional[type]\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_all(cls, values):\n",
    "        # inspect class init signature\n",
    "        obj_type = cls.__fields__[\"object\"].type_\n",
    "        \n",
    "        # adjust for re init from json\n",
    "        if \"loader\" not in values:\n",
    "            loader = CallableModel(callable=obj_type, **values)\n",
    "\n",
    "        else:\n",
    "            # validate loader callable is same as obj type\n",
    "            if values[\"loader\"].get(\"callable\") is not None:\n",
    "                # unparameterized callable will handle parsing\n",
    "                callable = CallableModel(\n",
    "                    callable=values[\"loader\"][\"callable\"]\n",
    "                )\n",
    "                \n",
    "                if not callable.callable is obj_type:\n",
    "                    raise ValueError(\n",
    "                        \"Provided loader of type %s. ObjLoader parameterized for %s\",\n",
    "                        callable.callable.__name__,\n",
    "                        obj_type,\n",
    "                    )\n",
    "\n",
    "                # opt for obj type\n",
    "                values[\"loader\"].pop(\"callable\")\n",
    "\n",
    "            # re-init drop callable from loader vals to use new instance\n",
    "            loader = CallableModel(callable=obj_type, **values[\"loader\"])\n",
    "\n",
    "        # update the class json encoders. Will only execute on initial type construction\n",
    "        if obj_type not in cls.__config__.json_encoders:\n",
    "            cls.__config__.json_encoders[obj_type] = cls.__config__.json_encoders.pop(\n",
    "                ObjType\n",
    "            )\n",
    "        return {\"object_type\": obj_type, \"loader\": loader}\n",
    "\n",
    "    def load(self, store: bool = False):\n",
    "        # store object reference on loader\n",
    "        if store:\n",
    "            self.object = self.loader.call()\n",
    "            return self.object\n",
    "\n",
    "        # return loaded object w/o storing\n",
    "        else:\n",
    "            return self.loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test object loader on our `TestClass`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_loader = ObjLoader[TestClass](x=1, y=3)\n",
    "loaded = obj_loader.load()\n",
    "loaded.x\n",
    "loaded.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can do this for a generic object like `ThreadPoolExecutor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_loader = ObjLoader[ThreadPoolExecutor](max_workers=1)\n",
    "tpe = tpe_loader.load()\n",
    "tpe\n",
    "tpe_loader_json  = tpe_loader.json()\n",
    "tpe_loader_json\n",
    "tpe_loader_from_json = ObjLoader[ThreadPoolExecutor].parse_raw(tpe_loader_json)\n",
    "\n",
    "\n",
    "# shutdown tpe\n",
    "tpe.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executors\n",
    "The previous classes were an attempt to demonstrate generic utility. The Executors to follow will build off of those common utilities to parameterize generic executors complying with the pep-3148 standard (the callables have been typified in case of deviation). Likewise, the following BaseExecutor outlines common executor fields and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# COMMON BASE FOR EXECUTORS\n",
    "class BaseExecutor(\n",
    "    GenericModel,\n",
    "    Generic[ObjType],\n",
    "    arbitrary_types_allowed=True,\n",
    "    json_encoders=JSON_ENCODERS,\n",
    "):\n",
    "    # executor_type must comply with https://peps.python.org/pep-3148/ standard\n",
    "    loader: Optional[ObjLoader[ObjType]] # loader of executor type\n",
    "\n",
    "    # This is a utility field not included in reps. The typing lib has opened issues on access of generic type within class.\n",
    "    # This tracks for if-necessary future use.\n",
    "    executor_type: type = Field(None, exclude=True) \n",
    "    submit_callable: str = \"submit\"\n",
    "    map_callable: str = \"map\"\n",
    "    shutdown_callable: str = \"shutdown\"\n",
    "\n",
    "    # executor will not be explicitely serialized, but loaded using loader with class\n",
    "    # and kwargs\n",
    "    executor: Optional[ObjType]\n",
    "\n",
    "    @root_validator(pre=True)\n",
    "    def validate_all(cls, values):\n",
    "        executor_type = cls.__fields__[\"executor\"].type_ # introspect fields to get type\n",
    "\n",
    "        # check if executor provided\n",
    "        executor = values.get(\"executor\")\n",
    "        if executor is not None:\n",
    "            values.pop(\"executor\")\n",
    "        \n",
    "        # VALIDATE SUBMIT CALLABLE AGAINST EXECUTOR TYPE\n",
    "        if \"submit_callable\" not in values:\n",
    "            # use default\n",
    "            submit_callable = cls.__fields__[\"submit_callable\"].default\n",
    "        else:\n",
    "            submit_callable = values.pop(\"submit_callable\")\n",
    "\n",
    "        try:\n",
    "            getattr(executor_type, submit_callable)\n",
    "        except AttributeError:\n",
    "            raise ValueError(\n",
    "                \"Executor type %s has no submit method %s.\",\n",
    "                executor_type.__name__,\n",
    "                submit_callable,\n",
    "            )\n",
    "\n",
    "        # VALIDATE MAP CALLABLE AGAINST EXECUTOR TYPE\n",
    "        if not values.get(\"map_callable\"):\n",
    "            # use default\n",
    "            map_callable = cls.__fields__[\"map_callable\"].default\n",
    "        else:\n",
    "            map_callable = values.pop(\"map_callable\")\n",
    "\n",
    "        try:\n",
    "            getattr(executor_type, map_callable)\n",
    "        except AttributeError:\n",
    "            raise ValueError(\n",
    "                \"Executor type %s has no map method %s.\",\n",
    "                executor_type.__name__,\n",
    "                map_callable,\n",
    "            )\n",
    "\n",
    "        # VALIDATE SHUTDOWN CALLABLE AGAINST EXECUTOR TYPE\n",
    "        if not values.get(\"shutdown_callable\"):\n",
    "            # use default\n",
    "            shutdown_callable = cls.__fields__[\"shutdown_callable\"].default\n",
    "        else:\n",
    "            shutdown_callable = values.pop(\"shutdown_callable\")\n",
    "\n",
    "        try:\n",
    "            getattr(executor_type, shutdown_callable)\n",
    "        except AttributeError:\n",
    "            raise ValueError(\n",
    "                \"Executor type %s has no shutdown method %s.\",\n",
    "                executor_type.__name__,\n",
    "                shutdown_callable,\n",
    "            )\n",
    "\n",
    "        # Compose loader utility\n",
    "        if values.get(\"loader\") is not None:\n",
    "            loader_values = values.get(\"loader\")\n",
    "            loader = ObjLoader[executor_type](**loader_values)\n",
    "\n",
    "        else:\n",
    "            # maintain reference to original object\n",
    "            loader_values = copy.copy(values)\n",
    "\n",
    "            # if executor in values, need to remove\n",
    "            if \"executor\" in loader_values:\n",
    "                loader_values.pop(\"executor\")\n",
    "\n",
    "            loader = ObjLoader[executor_type](**loader_values)\n",
    "\n",
    "        # update encoders\n",
    "        # update the class json encoders. Will only execute on initial type construction\n",
    "        if executor_type not in cls.__config__.json_encoders:\n",
    "            cls.__config__.json_encoders[\n",
    "                executor_type\n",
    "            ] = cls.__config__.json_encoders.pop(ObjType)\n",
    "\n",
    "        return {\n",
    "            \"executor_type\": executor_type,\n",
    "            \"submit_callable\": submit_callable,\n",
    "            \"shutdown_callable\": shutdown_callable,\n",
    "            \"map_callable\": map_callable,\n",
    "            \"loader\": loader,\n",
    "            \"executor\": executor,\n",
    "        }\n",
    "\n",
    "    def shutdown(self) -> None:\n",
    "        shutdown_fn = getattr(self.executor, self.shutdown_callable)\n",
    "        shutdown_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal, ContextExecutor\n",
    "Now, we subclass base to create two executors: `NormalExecutor`, and `ContextExecutor`. In the case that the user would like to create a persistent executor passed to the Evaluator, they would use the NormalExecutor. The ContextExecutor provides a context manager to dynamically create executor instances during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NormalExecutor with no context handling on submission and executor persistence\n",
    "class NormalExecutor(\n",
    "    BaseExecutor[ObjType],\n",
    "    Generic[ObjType],\n",
    "    arbitrary_types_allowed=True,\n",
    "    json_encoders=JSON_ENCODERS,\n",
    "):\n",
    "\n",
    "    @validator(\"executor\", always=True)\n",
    "    def validate_executor(cls, v, values):\n",
    "\n",
    "        if v is None:\n",
    "            v = values[\"loader\"].load()\n",
    "\n",
    "        # if not None, validate against executor type\n",
    "        else:\n",
    "            if not isinstance(v, (values[\"executor_type\"],)):\n",
    "                raise ValueError(\n",
    "                    \"Provided executor is not instance of %s\",\n",
    "                    values[\"executor_type\"].__name__,\n",
    "                )\n",
    "\n",
    "        return v\n",
    "\n",
    "    def submit(self, fn, **kwargs) -> Future:\n",
    "        submit_fn = getattr(self.executor, self.submit_callable)\n",
    "        return submit_fn(fn, **kwargs)\n",
    "\n",
    "    def map(self, fn, iter: Iterable) -> Iterable[Future]:\n",
    "        map_fn = getattr(self.executor, self.map_callable)\n",
    "        return map_fn(fn, *iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some NormalExecutors: (must manually shutdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x113b87970 state=finished returned int>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ThreadPool\n",
    "tpe_exec = NormalExecutor[ThreadPoolExecutor](max_workers=1)\n",
    "# submit\n",
    "tpe_exec.submit(fn=test_function, x=1, y=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Executor.map.<locals>.result_iterator at 0x114923dd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map\n",
    "tpe_exec.map(test_function, ((1, 4), (3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpe_exec.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 13:20:27,006 - distributed.diskutils - INFO - Found stale lock file and directory '/Users/chrisonian/Code/GitHub/jackie-Xopt/dask-worker-space/worker-jg0jp28d', purging\n",
      "2022-05-31 13:20:27,006 - distributed.diskutils - INFO - Found stale lock file and directory '/Users/chrisonian/Code/GitHub/jackie-Xopt/dask-worker-space/worker-uzsv2_8d', purging\n",
      "2022-05-31 13:20:27,006 - distributed.diskutils - INFO - Found stale lock file and directory '/Users/chrisonian/Code/GitHub/jackie-Xopt/dask-worker-space/worker-3e_2qujq', purging\n",
      "2022-05-31 13:20:27,006 - distributed.diskutils - INFO - Found stale lock file and directory '/Users/chrisonian/Code/GitHub/jackie-Xopt/dask-worker-space/worker-1czlowi0', purging\n",
      "2022-05-31 13:20:27,007 - distributed.diskutils - INFO - Found stale lock file and directory '/Users/chrisonian/Code/GitHub/jackie-Xopt/dask-worker-space/worker-0ygv01z1', purging\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Future at 0x117a7b3d0 state=pending>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dask\n",
    "from distributed import Client\n",
    "from distributed.cfexecutor import ClientExecutor\n",
    "\n",
    "# Using an existing executor\n",
    "client = Client(silence_logs=logging.ERROR)\n",
    "executor = client.get_executor()\n",
    "\n",
    "dask_executor = NormalExecutor[type(executor)](executor=executor)\n",
    "dask_executor.submit(fn=test_function, x=1, y=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dask_executor.map(test_function, ((1, 4), (3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loader\": {\"object\": null, \"loader\": {\"callable\": \"distributed.cfexecutor:ClientExecutor\", \"kwargs\": {\"client\": \"inspect:_empty\"}}, \"object_type\": \"distributed.cfexecutor:ClientExecutor\"}, \"submit_callable\": \"submit\", \"map_callable\": \"map\", \"shutdown_callable\": \"shutdown\", \"executor\": \"distributed.cfexecutor:ClientExecutor\"}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_executor_json = dask_executor.json()\n",
    "dask_executor_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_executor.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this raises error because client not passed...\n",
    "try:\n",
    "    dask_executor_from_json = NormalExecutor[ClientExecutor].parse_raw(dask_executor_json)\n",
    "except ValidationError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context managers handle shutdown for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ContexExecutor with context handling on submission and no executor persistence\n",
    "class ContextExecutor(\n",
    "    BaseExecutor[ObjType],\n",
    "    Generic[ObjType],\n",
    "    arbitrary_types_allowed=True,\n",
    "    json_encoders=JSON_ENCODERS,\n",
    "):\n",
    "    @contextlib.contextmanager\n",
    "    def context(self):\n",
    "\n",
    "        try:\n",
    "            self.executor = self.loader.load()\n",
    "            yield self.executor\n",
    "\n",
    "        finally:\n",
    "            self.shutdown()\n",
    "            self.executor = None\n",
    "\n",
    "    def submit(self, fn, **kwargs) -> Future:\n",
    "        with self.context() as ctxt:\n",
    "            submit_fn = getattr(ctxt, self.submit_callable)\n",
    "            return submit_fn(fn, **kwargs)\n",
    "        \n",
    "    def map(self, fn, iter: Iterable) -> Iterable[Future]:\n",
    "        with self.context() as ctxt:\n",
    "            map_fn = getattr(ctxt, self.map_callable)\n",
    "            return map_fn(fn, iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some ContextExecutors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x16a789e20 state=finished returned int>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ThreadPoolExecutor\n",
    "context_exec = ContextExecutor[ThreadPoolExecutor](max_workers=1)\n",
    "context_exec.submit(fn=test_function, x=1, y=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Executor.map.<locals>.result_iterator at 0x16a7ff5f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_exec.map(test_function, ((1, 4), (3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"loader\": {\"object\": null, \"loader\": {\"callable\": \"concurrent.futures.thread:ThreadPoolExecutor\", \"kwargs\": {\"max_workers\": 1, \"thread_name_prefix\": \"\", \"initializer\": null, \"initargs\": []}}, \"object_type\": \"concurrent.futures.thread:ThreadPoolExecutor\"}, \"submit_callable\": \"submit\", \"map_callable\": \"map\", \"shutdown_callable\": \"shutdown\", \"executor\": null}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_exec_json = context_exec.json()\n",
    "context_exec_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x16a792af0 state=finished returned int>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_exec_from_json = ContextExecutor[ThreadPoolExecutor].parse_raw(\n",
    "        context_exec_json\n",
    "    )\n",
    "context_exec_from_json.submit(fn=test_function, x=1, y=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Executor.map.<locals>.result_iterator at 0x16a58c6d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 13:22:11,326 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "2022-05-31 13:22:11,326 - distributed.nanny - ERROR - Worker process died unexpectedly\n",
      "Exception in thread Nanny stop queue watch:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/chrisonian/Code/mambaforge/envs/xopt-dev/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/chrisonian/Code/mambaforge/envs/xopt-dev/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/chrisonian/Code/mambaforge/envs/xopt-dev/lib/python3.9/site-packages/distributed/nanny.py\", line 860, in watch_stop_q\n",
      "    child_stop_q.close()\n",
      "  File \"/Users/chrisonian/Code/mambaforge/envs/xopt-dev/lib/python3.9/multiprocessing/queues.py\", line 143, in close\n",
      "    self._reader.close()\n",
      "  File \"/Users/chrisonian/Code/mambaforge/envs/xopt-dev/lib/python3.9/multiprocessing/connection.py\", line 182, in close\n",
      "    self._close()\n",
      "  File \"/Users/chrisonian/Code/mambaforge/envs/xopt-dev/lib/python3.9/multiprocessing/connection.py\", line 366, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    }
   ],
   "source": [
    "context_exec_from_json.map(test_function, ((1, 4), (3, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some executors are generated with Clients that manage sessions:\n",
    "** will require gathering results before shutdown..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "72034539424920dfb606fe3b820b3f27dca0cbf1c69938110810ec4641e275b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('xopt-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
