{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Optimization using BAX\n",
    "In this notebook we demonstrate the use of Xopt to perform Bayesian Algorithm Execution (BAX) as a means of minimizing the output of a simple test function. BAX is a generalization of Bayesian Optimization that seeks to acquire observations that provide our model with maximal information about our property of interest. In this simple example, our property of interest is the minimum function output and its location in input-space. See https://arxiv.org/pdf/2209.04587.pdf for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and random seeding for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigError",
     "evalue": "Validators defined with incorrect fields: validate_num_restarts (use check_fields=False if you're inheriting from the model and intended this)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConfigError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 10\u001B[0m\n\u001B[0;32m      6\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKMP_DUPLICATE_LIB_OK\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrue\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Xopt\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvocs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VOCS\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbax_generator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaxGenerator\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _version\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Xopt\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Evaluator\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Generator\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\base.py:10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Evaluator, validate_outputs\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Generator\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_generator\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# from xopt.generators import get_generator_and_defaults\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m XoptBaseModel\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\__init__.py:26\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# generators needing botorch\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 26\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian_exploration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     27\u001B[0m         BayesianExplorationGenerator,\n\u001B[0;32m     28\u001B[0m     )\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexpected_improvement\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     30\u001B[0m         ExpectedImprovementGenerator,\n\u001B[0;32m     31\u001B[0m     )\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmobo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MOBOGenerator\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian_exploration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianExplorationGenerator\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexpected_improvement\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExpectedImprovementGenerator\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmobo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MOBOGenerator\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_exploration.py:10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbotorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransforms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m concatenate_pending_points, t_batch_mode_transform\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tensor\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian_generator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianGenerator\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcustom_botorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstrained_acqusition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     ConstrainedMCAcquisitionFunction,\n\u001B[0;32m     13\u001B[0m )\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mBayesianExplorationGenerator\u001B[39;00m(BayesianGenerator):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:28\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mturbo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TurboState\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerators\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m rectilinear_domain_union, set_botorch_weights\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mxopt\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumerical_optimizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NumericalOptimizer, LBFGSOptimizer, GridOptimizer\n\u001B[0;32m     30\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger()\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mBayesianGenerator\u001B[39;00m(Generator, ABC):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\numerical_optimizer.py:20\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\" optimize a function to produce a number of candidate points that\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m        minimize the function\"\"\"\u001B[39;00m\n\u001B[0;32m     17\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mLBFGSOptimizer\u001B[39;00m(NumericalOptimizer):\n\u001B[0;32m     21\u001B[0m     name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLBFGS\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     22\u001B[0m     n_raw_samples: PositiveInt \u001B[38;5;241m=\u001B[39m Field(\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;241m20\u001B[39m,\n\u001B[0;32m     24\u001B[0m         description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumber of raw samples used to seed optimization\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     25\u001B[0m     )\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\pydantic\\main.py:241\u001B[0m, in \u001B[0;36mpydantic.main.ModelMetaclass.__new__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\mambaforge\\envs\\xopt-dev\\lib\\site-packages\\pydantic\\class_validators.py:189\u001B[0m, in \u001B[0;36mpydantic.class_validators.ValidatorGroup.check_for_unused\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mConfigError\u001B[0m: Validators defined with incorrect fields: validate_num_restarts (use check_fields=False if you're inheriting from the model and intended this)"
     ]
    }
   ],
   "source": [
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import torch\n",
    "\n",
    "from xopt import Xopt\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "\n",
    "from xopt.evaluator import Evaluator\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "#random seeds for reproducibility \n",
    "rand_seed = 2\n",
    "\n",
    "torch.manual_seed(rand_seed)\n",
    "np.random.seed(rand_seed) #only affects initial random observations through Xopt\n",
    "random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the test problem\n",
    "Here we define a simple optimization problem, where we attempt to minimize the sin\n",
    "function in the domian [0,2*pi]. Note that the function used to evaluate the\n",
    "objective function takes a dictionary as input and returns a dictionary as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# define variables and function objectives\n",
    "vocs = VOCS(\n",
    "    variables={\"x\": [0, 2 * math.pi]},\n",
    "    objectives={\"f\": \"MAXIMIZE\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a test function to optimize\n",
    "import numpy as np\n",
    "\n",
    "def sin_function(input_dict):\n",
    "    return {\"f\": np.sin(input_dict[\"x\"])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare BAX generator for Xopt\n",
    "Create a generator that uses the ExpectedInformationGain (InfoBAX) acquisition\n",
    "function to perform Bayesian Optimization. Note that we use minimization on a grid,\n",
    "so specifying the number of mesh points can negatively impact decision making time\n",
    "(especially in higher dimensional feature spaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.bax.algorithms import GridMinimize\n",
    "\n",
    "#Prepare BAX algorithm and generator options\n",
    "algorithm = GridMinimize(n_mesh_points=100)\n",
    "\n",
    "#construct BAX generator\n",
    "generator = BaxGenerator(vocs=vocs, algorithm=algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Evaluator and Xopt objects\n",
    "Create the Evaluator (which allows Xopt to interface with our test function) and finish constructing our Xopt object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct evaluator\n",
    "evaluator = Evaluator(function=sin_function)\n",
    "\n",
    "#construct Xopt optimizer\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and evaluate initial points\n",
    "To begin optimization, we must generate some random initial data points. The first call\n",
    "to `X.step()` will generate and evaluate a number of randomly points specified by the\n",
    " generator. Note that if we add data to xopt before calling `X.step()` by assigning\n",
    " the data to `X.data`, calls to `X.step()` will ignore the random generation and\n",
    " proceed to generating points via Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate initial points\n",
    "X.random_evaluate(3)\n",
    "\n",
    "# inspect the gathered data\n",
    "X.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do bayesian optimization steps\n",
    "To perform optimization we simply call `X.step()` in a loop. This allows us to do\n",
    "intermediate tasks in between optimization steps, such as examining the model and\n",
    "acquisition function at each step (as we demonstrate here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "n_steps = 3\n",
    "\n",
    "# test points for plotting\n",
    "test_x = torch.linspace(*X.vocs.bounds.flatten(),50).double()\n",
    "\n",
    "for i in range(5):\n",
    "    # get the Gaussian process model from the generator\n",
    "    model = X.generator.train_model()\n",
    "\n",
    "    # get acquisition function from generator\n",
    "    acq = X.generator.get_acquisition(model)\n",
    "\n",
    "    # calculate model posterior and acquisition function at each test point\n",
    "    # NOTE: need to add a dimension to the input tensor for evaluating the\n",
    "    # posterior and another for the acquisition function, see\n",
    "    # https://botorch.org/docs/batching for details\n",
    "    # NOTE: we use the `torch.no_grad()` environment to speed up computation by\n",
    "    # skipping calculations for backpropagation\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(test_x.unsqueeze(1))\n",
    "        acq_val = acq(test_x.reshape(-1,1,1))\n",
    "\n",
    "    # get mean function and confidence regions\n",
    "    mean = posterior.mean\n",
    "    l,u = posterior.mvn.confidence_region()\n",
    "\n",
    "    # plot model and acquisition function\n",
    "    fig,ax = plt.subplots(3,1,sharex=\"all\")\n",
    "\n",
    "    # plot model posterior\n",
    "    ax[0].plot(test_x, mean, label=\"Posterior mean\")\n",
    "    ax[0].fill_between(test_x, l, u,alpha=0.25, label=\"Posterior confidence region\")\n",
    "\n",
    "    # add data to model plot\n",
    "    ax[0].plot(X.data[\"x\"],X.data[\"f\"],\"C1o\", label=\"Training data\")\n",
    "\n",
    "    # plot true function\n",
    "    true_f = sin_function({\"x\": test_x})[\"f\"]\n",
    "    ax[0].plot(test_x, true_f,'--', label=\"Ground truth\")\n",
    "\n",
    "    # add legend\n",
    "    ax[0].legend()\n",
    "\n",
    "    # plot the function samples and their optima found by BAX\n",
    "    test_points = X.generator.algorithm_results[\"test_points\"]\n",
    "    posterior_samples = X.generator.algorithm_results[\"posterior_samples\"]\n",
    "    execution_paths = X.generator.algorithm_results[\"execution_paths\"]\n",
    "\n",
    "    label1 = 'Function Samples'\n",
    "    label2 = 'Sample Optima'\n",
    "    for i in range(X.generator.algorithm.n_samples):\n",
    "        samples, = ax[1].plot(test_points, posterior_samples[i], c='C0', alpha=0.3,\n",
    "                              label=label1)\n",
    "        optima = ax[1].scatter(*execution_paths[i], c='r', marker='x', s=80,\n",
    "                               label=label2,zorder=10)\n",
    "        label1 = None\n",
    "        label2 = None \n",
    "    \n",
    "    # add legend\n",
    "    ax[1].legend()\n",
    "    \n",
    "    # plot acquisition function\n",
    "    ax[2].plot(test_x, acq_val.flatten())\n",
    "\n",
    "    ax[0].set_ylabel(\"f\")\n",
    "    ax[1].set_ylabel(\"f\")\n",
    "    ax[2].set_ylabel(r\"$\\alpha(x)$\")\n",
    "    ax[2].set_xlabel(\"x\")\n",
    "\n",
    "    # do the optimization step\n",
    "    X.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the collected data\n",
    "X.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
