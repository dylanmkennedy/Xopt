{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-fidelity (MF) optimization\n",
    "\n",
    "In most cases it is better to do many cheap evaluations of an approximation to the target function than it is to only optimize the target function. This example demonstrates the 'multi-fidelity' capabilities of xopt. \n",
    "\n",
    "We follow the implementation of multi-fidelity bayesian optimization used in botorch https://botorch.org/tutorials/multi_fidelity_bo to optimize the synthetic test function AugmentedHartmann https://botorch.org/api/test_functions.html.\n",
    "\n",
    "The difference between normal Bayesian optimization and MF optimization is that we specify a 'cost' to making observations at a given fidelity. For this example we assume a base cost of 5 and a fidelity cost between 0-1. The algorithm should make many observations at lower fidelity relative to higher fidelity, lowering the total observation cost. \n",
    "\n",
    "NOTE: The cost parameter is required to be the LAST element of the variables list. Also this method is best suited for parallel observations of the test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt import Xopt\n",
    "from xopt.bayesian.generators.multi_fidelity import MultiFidelityGenerator\n",
    "from xopt.bayesian.models.models import create_multi_fidelity_model\n",
    "from botorch.test_functions.multi_fidelity import AugmentedHartmann\n",
    "import logging\n",
    "import os\n",
    "SMOKE_TEST = os.environ.get('SMOKE_TEST')\n",
    "\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see log messages\n",
    "from xopt import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Xopt` object can be instantiated from a JSON or YAML file, or a dict, with the proper structure.\n",
    "\n",
    "Here we will make one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a proper input file. \n",
    "import yaml\n",
    "YAML = \"\"\"\n",
    "xopt: {output_path: null}\n",
    "\n",
    "algorithm:\n",
    "  name: multi_fidelity\n",
    "  options:  \n",
    "      processes: 4\n",
    "      budget: 32\n",
    "      generator_options: {}\n",
    "\n",
    "simulation: \n",
    "  name: test_multi_fidelity\n",
    "  evaluate: xopt.tests.evaluators.multi_fidelity.evaluate\n",
    "\n",
    "vocs:\n",
    "  description: null\n",
    "  templates: null\n",
    "  variables:\n",
    "    x1: [0, 1.0]\n",
    "    x2: [0, 1.0]\n",
    "    x3: [0, 1.0]\n",
    "    x4: [0, 1.0]\n",
    "    x5: [0, 1.0]\n",
    "    x6: [0, 1.0]\n",
    "    cost: [0, 1.0]                          ## NOTE: THIS IS REQUIRED FOR MULTI-FIDELITY OPTIMIZATION\n",
    "  objectives:\n",
    "    y1: 'MINIMIZE'\n",
    "  linked_variables: {}\n",
    "  constants: {a: dummy_constant}\n",
    "\n",
    "\"\"\"\n",
    "config = yaml.safe_load(YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from dict.\n",
      "Loading config from dict.\n",
      "Loading config from dict.\n",
      "Loading config from dict.\n",
      "Loading config from dict.\n",
      "`description` keyword no longer allowed in vocs config, removing\n",
      "`templates` keyword no longer allowed in vocs config, moving to simulation `options`\n",
      "Warning: No path set for key xopt : output_path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "            Xopt \n",
       "________________________________           \n",
       "Version: 0.4.3+221.g8413e80.dirty\n",
       "Configured: True\n",
       "Config as YAML:\n",
       "xopt: {output_path: null}\n",
       "algorithm:\n",
       "  name: multi_fidelity\n",
       "  options:\n",
       "    processes: 4\n",
       "    budget: 32\n",
       "    generator_options: {}\n",
       "    base_cost: 1.0\n",
       "  function: xopt.bayesian.algorithms.multi_fidelity_optimize\n",
       "simulation:\n",
       "  name: test_multi_fidelity\n",
       "  evaluate: xopt.tests.evaluators.multi_fidelity.evaluate\n",
       "  options: {templates: null, extra_option: abc}\n",
       "vocs:\n",
       "  variables:\n",
       "    x1: [0, 1.0]\n",
       "    x2: [0, 1.0]\n",
       "    x3: [0, 1.0]\n",
       "    x4: [0, 1.0]\n",
       "    x5: [0, 1.0]\n",
       "    x6: [0, 1.0]\n",
       "    cost: [0, 1.0]\n",
       "  objectives: {y1: MINIMIZE}\n",
       "  linked_variables: {}\n",
       "  constants: {a: dummy_constant}\n",
       "  constraints: null"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if SMOKE_TEST:\n",
    "    config['algorithm']['options']['budget'] = 3\n",
    "    config['algorithm']['options']['processes'] = 1\n",
    "    config['algorithm']['options']['generator_options']['num_restarts'] = 2\n",
    "    config['algorithm']['options']['generator_options']['raw_samples'] = 2\n",
    "    config['algorithm']['options']['generator_options']['base_acq'] = None\n",
    "\n",
    "X = Xopt(config)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run BayesOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of these\n",
    "from concurrent.futures import ThreadPoolExecutor as PoolExecutor\n",
    "#from concurrent.futures import ProcessPoolExecutor \n",
    "\n",
    "executor = PoolExecutor()\n",
    "# This will also work. \n",
    "# executor=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at time 2021-10-08T15:27:05-07:00\n",
      "started running optimization with generator: <xopt.bayesian.generators.multi_fidelity.MultiFidelityGenerator object at 0x12c30dd00>\n",
      "starting optimization loop\n",
      "Submitted candidate   0, cost: 1.26, total cost: 1.26\n",
      "Submitted candidate   1, cost: 1.11, total cost: 2.372\n",
      "Submitted candidate   2, cost:  1.1, total cost: 3.468\n",
      "Submitted candidate   3, cost: 1.13, total cost: 4.598\n",
      "generating 4 new candidate(s)\n",
      "Submitted candidate   4, cost:  1.0, total cost: 5.598\n",
      "Submitted candidate   5, cost:  1.0, total cost: 6.598\n",
      "Submitted candidate   6, cost:  1.0, total cost: 7.598\n",
      "Submitted candidate   7, cost:  1.0, total cost: 8.598\n",
      "generating 4 new candidate(s)\n",
      "Submitted candidate   8, cost: 1.01, total cost: 9.611\n",
      "Submitted candidate   9, cost:  1.0, total cost: 10.61\n",
      "Submitted candidate  10, cost:  1.0, total cost: 11.61\n",
      "Submitted candidate  11, cost:  1.0, total cost: 12.61\n",
      "generating 4 new candidate(s)\n",
      "Submitted candidate  12, cost: 1.02, total cost: 13.63\n",
      "Submitted candidate  13, cost:  1.0, total cost: 14.63\n",
      "Submitted candidate  14, cost:  1.0, total cost: 15.63\n",
      "Submitted candidate  15, cost:  1.0, total cost: 16.63\n",
      "generating 3 new candidate(s)\n",
      "Submitted candidate  16, cost: 1.01, total cost: 17.64\n",
      "Submitted candidate  17, cost:  1.0, total cost: 18.64\n",
      "Submitted candidate  18, cost:  1.0, total cost: 19.64\n",
      "generating 1 new candidate(s)\n",
      "Submitted candidate  19, cost: 1.01, total cost: 20.65\n",
      "generating 3 new candidate(s)\n",
      "Submitted candidate  20, cost: 1.02, total cost: 21.67\n",
      "Submitted candidate  21, cost:  1.0, total cost: 22.67\n",
      "Submitted candidate  22, cost: 1.02, total cost: 23.69\n",
      "generating 1 new candidate(s)\n",
      "Submitted candidate  23, cost: 1.04, total cost: 24.73\n",
      "generating 3 new candidate(s)\n",
      "Submitted candidate  24, cost: 1.17, total cost: 25.9\n",
      "Submitted candidate  25, cost: 1.19, total cost: 27.09\n",
      "Submitted candidate  26, cost: 1.13, total cost: 28.21\n",
      "generating 1 new candidate(s)\n",
      "Submitted candidate  27, cost: 1.27, total cost: 29.48\n",
      "generating 3 new candidate(s)\n",
      "Submitted candidate  28, cost: 1.23, total cost: 30.72\n",
      "Submitted candidate  29, cost: 1.33, total cost: 32.04\n",
      "budget exceeded, waiting for simulations to end\n",
      "Budget exceeded and simulations finished\n",
      "CPU times: user 22min 54s, sys: 1min 11s, total: 24min 6s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "X.run(executor=executor)\n",
    "results = X.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get highest fidelity global optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create generator object\n",
    "gen = MultiFidelityGenerator(X.vocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = create_multi_fidelity_model(results['variables'],\n",
    "                                    results['corrected_objectives'],\n",
    "                                    None,\n",
    "                                    X.vocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2211], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE: we want to get the minimum evaluated at the highest fidelity -> make sure to use get_recommendation\n",
    "rec = gen.get_recommendation(model)\n",
    "problem = AugmentedHartmann(negate=False)\n",
    "problem(rec) ## NOTE: the correct global minimum is -3.32237"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
