{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xopt class, TNK test function\n",
    "\n",
    "This is the class method for running Xopt.\n",
    "\n",
    "TNK function\n",
    "$n=2$ variables:\n",
    "$x_i \\in [0, \\pi], i=1,2$\n",
    "\n",
    "Objectives:\n",
    "- $f_i(x) = x_i$\n",
    "\n",
    "Constraints:\n",
    "- $g_1(x) = -x_1^2 -x_2^2 + 1 + 0.1 \\cos\\left(16 \\arctan \\frac{x_1}{x_2}\\right) \\le 0$\n",
    "- $g_2(x) = (x_1 - 1/2)^2 + (x_2-1/2)^2 \\le 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the class\n",
    "from xopt import Xopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Xopt` object can be instantiated from a JSON or YAML file, or a dict, with the proper structure.\n",
    "\n",
    "Here we will make one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "# Make a proper input file. \n",
    "YAML=\"\"\"\n",
    "xopt: {output_path: null, verbose: true}\n",
    "\n",
    "algorithm:\n",
    "  name: mobo\n",
    "  options: {ref: [1.4, 1.4],\n",
    "            n_initial_samples: 5,\n",
    "            batch_size: 4,\n",
    "            mc_samples: 128,\n",
    "            use_gpu: False,\n",
    "            n_steps: 50, \n",
    "            verbose: True}\n",
    "  \n",
    "simulation: \n",
    "  name: test_TNK\n",
    "  evaluate: xopt.evaluators.test_TNK.evaluate_TNK  \n",
    "  \n",
    "vocs:\n",
    "  name: TNK_test\n",
    "  description: null\n",
    "  simulation: test_TNK\n",
    "  templates: null\n",
    "  variables:\n",
    "    x1: [0, 3.14159]\n",
    "    x2: [0, 3.14159]\n",
    "  objectives: {y1: MINIMIZE, y2: MINIMIZE}\n",
    "  constraints:\n",
    "    c1: [GREATER_THAN, 0]\n",
    "    c2: ['LESS_THAN', 0.5]\n",
    "  linked_variables: {x9: x1}\n",
    "  constants: {a: dummy_constant}\n",
    "\n",
    "\"\"\"\n",
    "config = yaml.safe_load(YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config as dict.\n",
      "Warning: No path set for key xopt : output_path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "            Xopt \n",
       "________________________________           \n",
       "Version: 0.4.3\n",
       "Configured: True\n",
       "Config as YAML:\n",
       "xopt: {output_path: null, verbose: true}\n",
       "algorithm:\n",
       "  name: mobo\n",
       "  function: xopt.mobo.mobo\n",
       "  options:\n",
       "    ref: [1.4, 1.4]\n",
       "    n_initial_samples: 5\n",
       "    batch_size: 4\n",
       "    mc_samples: 128\n",
       "    use_gpu: false\n",
       "    n_steps: 50\n",
       "    verbose: true\n",
       "    executor: null\n",
       "    model_options: null\n",
       "    seed: null\n",
       "    return_model: false\n",
       "    initial_x: null\n",
       "    plot_acq: false\n",
       "simulation:\n",
       "  name: test_TNK\n",
       "  evaluate: xopt.evaluators.test_TNK.evaluate_TNK\n",
       "  options: {extra_option: abc}\n",
       "vocs:\n",
       "  name: TNK_test\n",
       "  description: null\n",
       "  simulation: test_TNK\n",
       "  templates: null\n",
       "  variables:\n",
       "    x1: [0, 3.14159]\n",
       "    x2: [0, 3.14159]\n",
       "  objectives: {y1: MINIMIZE, y2: MINIMIZE}\n",
       "  constraints:\n",
       "    c1: [GREATER_THAN, 0]\n",
       "    c2: [LESS_THAN, 0.5]\n",
       "  linked_variables: {x9: x1}\n",
       "  constants: {a: dummy_constant}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Connect the function directly\n",
    "#from xopt.evaluators.test_TNK import evaluate_TNK \n",
    "#config['simulation']['evaluate'] = evaluate_TNK \n",
    "\n",
    "X = Xopt(config)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y1': 2.7919907666820896,\n",
       " 'y2': 0.761814760901189,\n",
       " 'c1': 7.419108670852612,\n",
       " 'c2': 5.3217686435816995,\n",
       " 'some_array': array([1, 2, 3])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the repr string contains all of the config information\n",
    "X.random_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MOBO\n",
    "\n",
    "MOBO is designed to run in serial or parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of these\n",
    "from concurrent.futures import ThreadPoolExecutor as PoolExecutor\n",
    "#from concurrent.futures import ProcessPoolExecutor as PoolExecutor\n",
    "\n",
    "executor = PoolExecutor()\n",
    "# This will also work. \n",
    "#executor=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at time 2021-08-03T10:43:14-05:00\n",
      "n_feas: 2\n",
      "tensor([[0.0000, 0.9017],\n",
      "        [0.6146, 0.9567],\n",
      "        [0.0000, 1.5208],\n",
      "        [0.4651, 0.1822]], dtype=torch.float64)\n",
      "Step : 0, hypervolume : 0.22852773615524868\n",
      "n_feas: 4\n",
      "tensor([[0.7998, 0.5829],\n",
      "        [0.1984, 1.0925],\n",
      "        [0.8941, 0.0000],\n",
      "        [0.0000, 0.0000]], dtype=torch.float64)\n",
      "Step : 1, hypervolume : 0.394881644412827\n",
      "n_feas: 7\n",
      "tensor([[0.0523, 1.0182],\n",
      "        [1.0545, 0.2513],\n",
      "        [0.9902, 0.4568],\n",
      "        [0.5143, 0.8173]], dtype=torch.float64)\n",
      "Step : 2, hypervolume : 0.7004804154424585\n",
      "n_feas: 10\n",
      "tensor([[0.0611, 1.0377],\n",
      "        [1.0089, 0.0425],\n",
      "        [0.2220, 0.9463],\n",
      "        [0.6569, 0.6794]], dtype=torch.float64)\n",
      "Step : 3, hypervolume : 0.8766019689630744\n",
      "n_feas: 12\n",
      "tensor([[1.0334, 0.0741],\n",
      "        [0.8525, 0.2250],\n",
      "        [0.0000, 0.3984],\n",
      "        [0.7381, 0.4151]], dtype=torch.float64)\n",
      "Step : 4, hypervolume : 0.9703849604446289\n",
      "n_feas: 13\n",
      "tensor([[0.8310, 0.4938],\n",
      "        [0.7493, 0.6773],\n",
      "        [1.0004, 0.2553],\n",
      "        [0.1457, 0.9822]], dtype=torch.float64)\n",
      "Step : 5, hypervolume : 1.039643302372563\n",
      "n_feas: 16\n",
      "tensor([[0.9494, 0.2302],\n",
      "        [0.3821, 0.8764],\n",
      "        [0.0513, 1.0406],\n",
      "        [0.9834, 0.1472]], dtype=torch.float64)\n",
      "Step : 6, hypervolume : 1.0647233360310369\n",
      "n_feas: 19\n",
      "tensor([[0.1183, 0.0000],\n",
      "        [0.7731, 0.6414],\n",
      "        [1.0412, 0.0564],\n",
      "        [0.1481, 0.0000]], dtype=torch.float64)\n",
      "Step : 7, hypervolume : 1.086291534598387\n",
      "n_feas: 21\n",
      "tensor([[0.5576, 0.7920],\n",
      "        [0.1967, 0.9356],\n",
      "        [0.7949, 0.5490],\n",
      "        [0.9921, 0.1003]], dtype=torch.float64)\n",
      "Step : 8, hypervolume : 1.0973570789600935\n",
      "n_feas: 25\n",
      "tensor([[0.9348, 0.2479],\n",
      "        [0.9719, 0.1291],\n",
      "        [0.5691, 0.7799],\n",
      "        [0.1030, 0.9981]], dtype=torch.float64)\n",
      "Step : 9, hypervolume : 1.1086236917549444\n",
      "n_feas: 28\n",
      "tensor([[0.0459, 1.0399],\n",
      "        [0.9409, 0.2172],\n",
      "        [0.4792, 0.8654],\n",
      "        [0.7816, 0.5774]], dtype=torch.float64)\n",
      "Step : 10, hypervolume : 1.114849087370728\n",
      "n_feas: 32\n",
      "tensor([[0.7544, 0.7383],\n",
      "        [0.9997, 0.0947],\n",
      "        [0.2470, 0.4170],\n",
      "        [0.8814, 0.4665]], dtype=torch.float64)\n",
      "Step : 11, hypervolume : 1.1227605874336162\n",
      "n_feas: 34\n",
      "tensor([[0.9513, 0.1642],\n",
      "        [0.1535, 0.9540],\n",
      "        [0.8050, 0.5167],\n",
      "        [0.0775, 1.0175]], dtype=torch.float64)\n",
      "Step : 12, hypervolume : 1.124700895074568\n",
      "n_feas: 38\n",
      "tensor([[1.0407, 0.0483],\n",
      "        [0.2021, 0.9293],\n",
      "        [0.4469, 0.5895],\n",
      "        [0.8794, 0.4786]], dtype=torch.float64)\n",
      "Step : 13, hypervolume : 1.128366484587412\n",
      "n_feas: 41\n",
      "tensor([[0.9114, 0.4598],\n",
      "        [0.4969, 0.8360],\n",
      "        [0.0428, 1.0401],\n",
      "        [0.9351, 0.2047]], dtype=torch.float64)\n",
      "Step : 14, hypervolume : 1.1339756786665276\n",
      "n_feas: 45\n",
      "tensor([[0.1690, 0.9408],\n",
      "        [0.9405, 0.1724],\n",
      "        [0.7885, 0.5400],\n",
      "        [0.9563, 0.1421]], dtype=torch.float64)\n",
      "Step : 15, hypervolume : 1.136654629595044\n",
      "n_feas: 49\n",
      "tensor([[0.9316, 0.2025],\n",
      "        [0.0630, 1.0274],\n",
      "        [0.8534, 0.4838],\n",
      "        [0.7334, 0.7591]], dtype=torch.float64)\n",
      "Step : 16, hypervolume : 1.1380426203085214\n",
      "n_feas: 53\n",
      "tensor([[0.1259, 0.9722],\n",
      "        [1.0406, 0.0438],\n",
      "        [0.7754, 0.5841],\n",
      "        [0.9296, 0.1993]], dtype=torch.float64)\n",
      "Step : 17, hypervolume : 1.1397998593448744\n",
      "n_feas: 56\n",
      "tensor([[0.5852, 0.7746],\n",
      "        [0.1532, 0.6965],\n",
      "        [0.3110, 0.4802],\n",
      "        [0.1991, 0.9264]], dtype=torch.float64)\n",
      "Step : 18, hypervolume : 1.1412937175462454\n",
      "n_feas: 57\n",
      "tensor([[0.6286, 0.0000],\n",
      "        [1.0215, 0.0708],\n",
      "        [0.1010, 0.9929],\n",
      "        [0.6023, 0.7715]], dtype=torch.float64)\n",
      "Step : 19, hypervolume : 1.1420806353463555\n",
      "n_feas: 59\n",
      "tensor([[0.4661, 0.8979],\n",
      "        [0.6006, 0.7722],\n",
      "        [0.1143, 0.9815],\n",
      "        [0.7624, 0.7139]], dtype=torch.float64)\n",
      "Step : 20, hypervolume : 1.1425605073659806\n",
      "n_feas: 63\n",
      "tensor([[0.8154, 0.5048],\n",
      "        [0.7716, 0.6014],\n",
      "        [0.7806, 0.5558],\n",
      "        [0.5991, 0.7725]], dtype=torch.float64)\n",
      "Step : 21, hypervolume : 1.143363243579327\n",
      "n_feas: 65\n",
      "tensor([[0.8913, 0.4696],\n",
      "        [0.4884, 0.8482],\n",
      "        [0.7949, 0.5256],\n",
      "        [0.0887, 1.0061]], dtype=torch.float64)\n",
      "Step : 22, hypervolume : 1.1437254959031034\n",
      "n_feas: 70\n",
      "tensor([[0.1384, 0.9598],\n",
      "        [0.5293, 0.7964],\n",
      "        [0.8028, 0.5126],\n",
      "        [0.7720, 0.6000]], dtype=torch.float64)\n",
      "Step : 23, hypervolume : 1.144338730285236\n",
      "n_feas: 74\n",
      "tensor([[0.5095, 0.8116],\n",
      "        [0.1306, 0.9651],\n",
      "        [0.5947, 0.7728],\n",
      "        [0.8708, 0.4761]], dtype=torch.float64)\n",
      "Step : 24, hypervolume : 1.1451913143209502\n",
      "n_feas: 76\n",
      "tensor([[0.1517, 0.9480],\n",
      "        [0.9282, 0.1968],\n",
      "        [0.9825, 0.1124],\n",
      "        [0.7129, 0.7647]], dtype=torch.float64)\n",
      "Step : 25, hypervolume : 1.1454509448668193\n",
      "n_feas: 79\n",
      "tensor([[0.7680, 0.6926],\n",
      "        [0.5437, 0.7850],\n",
      "        [0.7407, 0.7460],\n",
      "        [0.5971, 0.7728]], dtype=torch.float64)\n",
      "Step : 26, hypervolume : 1.1460554622704175\n",
      "n_feas: 82\n",
      "tensor([[0.9458, 0.1546],\n",
      "        [0.0541, 1.0333],\n",
      "        [0.8718, 0.1475],\n",
      "        [1.0400, 0.0439]], dtype=torch.float64)\n",
      "Step : 27, hypervolume : 1.1465803162089405\n",
      "n_feas: 85\n",
      "tensor([[0.2004, 0.9271],\n",
      "        [0.5943, 0.7729],\n",
      "        [1.0401, 0.0414],\n",
      "        [1.0111, 0.0827]], dtype=torch.float64)\n",
      "Step : 28, hypervolume : 1.1483546775008366\n",
      "n_feas: 86\n",
      "tensor([[0.7519, 0.7311],\n",
      "        [0.4728, 0.8824],\n",
      "        [0.9189, 0.4133],\n",
      "        [0.9624, 0.1318]], dtype=torch.float64)\n",
      "Step : 29, hypervolume : 1.1484788592919826\n",
      "n_feas: 89\n",
      "tensor([[0.7731, 0.5810],\n",
      "        [0.5011, 0.8228],\n",
      "        [0.6897, 0.7693],\n",
      "        [0.9502, 0.1465]], dtype=torch.float64)\n",
      "Step : 30, hypervolume : 1.1487716315307879\n",
      "n_feas: 92\n",
      "tensor([[0.1997, 0.9274],\n",
      "        [0.5183, 0.8013],\n",
      "        [0.7262, 0.7556],\n",
      "        [0.7835, 0.5434]], dtype=torch.float64)\n",
      "Step : 31, hypervolume : 1.149054985429655\n",
      "n_feas: 95\n",
      "tensor([[0.5987, 0.7729],\n",
      "        [0.9346, 0.1784],\n",
      "        [0.5043, 0.8156],\n",
      "        [0.1793, 0.9341]], dtype=torch.float64)\n",
      "Step : 32, hypervolume : 1.1493207252832627\n",
      "n_feas: 98\n",
      "tensor([[0.7734, 0.5796],\n",
      "        [1.0311, 0.0576],\n",
      "        [0.7574, 0.7222],\n",
      "        [0.5985, 0.7730]], dtype=torch.float64)\n",
      "Step : 33, hypervolume : 1.1496056101614591\n",
      "n_feas: 100\n",
      "tensor([[0.9738, 0.1208],\n",
      "        [0.5985, 0.7730],\n",
      "        [0.1195, 0.9751],\n",
      "        [0.7457, 0.7391]], dtype=torch.float64)\n",
      "Step : 34, hypervolume : 1.1497667877625124\n",
      "n_feas: 103\n",
      "tensor([[0.1687, 0.9164],\n",
      "        [0.5323, 0.7896],\n",
      "        [0.1775, 0.8834],\n",
      "        [0.6046, 0.8747]], dtype=torch.float64)\n",
      "Step : 35, hypervolume : 1.1499231392005913\n",
      "n_feas: 105\n",
      "tensor([[0.1596, 0.9424],\n",
      "        [0.1436, 0.9535],\n",
      "        [0.4934, 0.8333],\n",
      "        [0.2656, 0.9317]], dtype=torch.float64)\n",
      "Step : 36, hypervolume : 1.1500000028638757\n",
      "n_feas: 108\n",
      "tensor([[0.1999, 0.9278],\n",
      "        [0.9573, 0.1369],\n",
      "        [0.9391, 0.1643],\n",
      "        [0.4756, 0.8737]], dtype=torch.float64)\n",
      "Step : 37, hypervolume : 1.1501668963331555\n",
      "n_feas: 110\n",
      "tensor([[0.8717, 0.4764],\n",
      "        [0.7626, 0.5281],\n",
      "        [0.8814, 0.4728],\n",
      "        [0.9774, 0.1161]], dtype=torch.float64)\n",
      "Step : 38, hypervolume : 1.1502606782713938\n",
      "n_feas: 114\n",
      "tensor([[0.7172, 0.7602],\n",
      "        [0.9281, 0.2011],\n",
      "        [0.9422, 0.1577],\n",
      "        [0.9594, 0.1348]], dtype=torch.float64)\n",
      "Step : 39, hypervolume : 1.1504044772384738\n",
      "n_feas: 117\n",
      "tensor([[0.1080, 0.9865],\n",
      "        [0.4585, 0.9137],\n",
      "        [1.0398, 0.0415],\n",
      "        [0.9913, 0.1066]], dtype=torch.float64)\n",
      "Step : 40, hypervolume : 1.1504910813491522\n",
      "n_feas: 120\n",
      "tensor([[0.7737, 0.5767],\n",
      "        [0.5666, 0.5788],\n",
      "        [1.0161, 0.0761],\n",
      "        [0.1246, 0.9691]], dtype=torch.float64)\n",
      "Step : 41, hypervolume : 1.1506973744803293\n",
      "n_feas: 122\n",
      "tensor([[0.7726, 0.5938],\n",
      "        [0.7545, 0.6224],\n",
      "        [0.7887, 0.5309],\n",
      "        [0.5209, 1.0846]], dtype=torch.float64)\n",
      "Step : 42, hypervolume : 1.1507554045881465\n",
      "n_feas: 124\n",
      "tensor([[0.0430, 1.0399],\n",
      "        [0.1288, 1.6526],\n",
      "        [0.7335, 0.7501],\n",
      "        [0.4536, 0.9205]], dtype=torch.float64)\n",
      "Step : 43, hypervolume : 1.1508117290037736\n",
      "n_feas: 126\n",
      "tensor([[0.9281, 0.2016],\n",
      "        [0.7729, 0.5932],\n",
      "        [1.1573, 0.0116],\n",
      "        [0.4691, 0.8895]], dtype=torch.float64)\n",
      "Step : 44, hypervolume : 1.1508944118580229\n",
      "n_feas: 127\n",
      "tensor([[0.2176, 0.9131],\n",
      "        [0.2828, 0.8167],\n",
      "        [0.7729, 0.5930],\n",
      "        [0.7768, 0.5639]], dtype=torch.float64)\n",
      "Step : 45, hypervolume : 1.1509259396130267\n",
      "n_feas: 128\n",
      "tensor([[0.8618, 0.4800],\n",
      "        [0.5124, 0.8050],\n",
      "        [0.5999, 0.7730],\n",
      "        [0.6401, 0.7715]], dtype=torch.float64)\n",
      "Step : 46, hypervolume : 1.1510026580835615\n",
      "n_feas: 130\n",
      "tensor([[9.2817e-01, 2.0135e-01],\n",
      "        [9.2877e-01, 1.9592e-01],\n",
      "        [9.9374e-01, 1.0062e-01],\n",
      "        [1.3560e+00, 4.0470e-04]], dtype=torch.float64)\n",
      "Step : 47, hypervolume : 1.151079519434697\n",
      "n_feas: 131\n",
      "tensor([[0.6000, 0.7730],\n",
      "        [0.9317, 0.1846],\n",
      "        [0.6652, 0.7598],\n",
      "        [0.6306, 0.7720]], dtype=torch.float64)\n",
      "Step : 48, hypervolume : 1.1511151202191665\n",
      "n_feas: 132\n",
      "tensor([[0.7730, 0.5929],\n",
      "        [0.6002, 0.7731],\n",
      "        [1.0945, 0.4183],\n",
      "        [0.8280, 0.4927]], dtype=torch.float64)\n",
      "Step : 49, hypervolume : 1.1511575958421456\n"
     ]
    }
   ],
   "source": [
    "# Change max generations\n",
    "X.run(executor=executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18eb022ee50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot objective results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "train_y = X.results[1].numpy()\n",
    "\n",
    "ax.plot(*train_y.T, '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopt",
   "language": "python",
   "name": "xopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
