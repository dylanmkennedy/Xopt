{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# TuRBO Bayesian Optimization\n",
    "In this tutorial we demonstrate the use of Xopt to preform Trust Region Bayesian\n",
    "Optimization (TuRBO) on a simple test problem. During optimization of high\n",
    "dimensional input spaces off the shelf BO tends to over-emphasize exploration which\n",
    "severely degrades optimization performance. TuRBO attempts to prevent this by\n",
    "maintaining a surrogate model over a local (trust) region centered on the best\n",
    "observation so far and restricting optimization inside that local region. The trust\n",
    "region is expanded and contracted based on the number of `successful` (observations\n",
    "that improve over the best observed point) or `unsuccessful` (no improvement)\n",
    "observations in a row. See https://botorch.org/tutorials/turbo_1 for details."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the test problem\n",
    "Here we define a simple optimization problem, where we attempt to minimize a\n",
    "function in the domian [0,2*pi]. Note that the function used to evaluate the\n",
    "objective function takes a dictionary as input and returns a dictionary as the output."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from xopt.vocs import VOCS\n",
    "import math\n",
    "\n",
    "# define variables and function objectives\n",
    "vocs = VOCS(\n",
    "    variables={\"x\": [0, 2 * math.pi]},\n",
    "    objectives={\"f\": \"MINIMIZE\"},\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# define a test function to optimize\n",
    "import numpy as np\n",
    "\n",
    "def sin_function(input_dict):\n",
    "    x = input_dict[\"x\"]\n",
    "    return {\"f\": -10*np.exp(-(x - np.pi)**2 / 0.01) + 0.5*np.sin(5*x)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Xopt objects\n",
    "Create the evaluator to evaluate our test function and create a generator that uses\n",
    "the Upper Confidence Bound acqusition function to perform Bayesian Optimization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from xopt.evaluator import Evaluator\n",
    "from xopt.generators.bayesian import UpperConfidenceBoundGenerator\n",
    "from xopt.generators.bayesian.options import OptimizationOptions\n",
    "from xopt import Xopt\n",
    "\n",
    "\n",
    "evaluator = Evaluator(function=sin_function)\n",
    "generator = UpperConfidenceBoundGenerator(\n",
    "    vocs=vocs, optimization_options = OptimizationOptions(use_turbo=True)\n",
    ")\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\n            Xopt\n________________________________\nVersion: 1.4.0+1.g992f130.dirty\nData size: 0\nConfig as YAML:\nxopt: {asynch: false, strict: false, dump_file: null, max_evaluations: null}\ngenerator:\n  name: upper_confidence_bound\n  supports_batch_generation: true\n  model_constructor:\n    name: standard\n    use_low_noise_prior: true\n    covar_modules: {}\n    mean_modules: {}\n    dtype: torch.float64\n    device: cpu\n  optimization_options: {num_restarts: 20, raw_samples: 20, sequential: true, max_travel_distances: null,\n    use_turbo: true}\n  acquisition_options: {proximal_lengthscales: null, use_transformed_proximal_weights: true,\n    monte_carlo_samples: 128, beta: 2.0}\n  model: null\n  turbo_state: xopt.generators.bayesian.turbo.TurboState\n  use_cuda: false\nevaluator:\n  function: __main__.sin_function\n  max_workers: 1\n  function_kwargs: {}\n  vectorized: false\nvocs:\n  variables:\n    x: [0.0, 6.283185307179586]\n  constraints: {}\n  objectives: {f: MINIMIZE}\n  constants: {}\n  linked_variables: {}\n"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate and evaluate initial points\n",
    "To begin optimization, we must generate some random initial data points. The first call\n",
    "to `X.step()` will generate and evaluate a number of randomly points specified by the\n",
    " generator. Note that if we add data to xopt before calling `X.step()` by assigning\n",
    " the data to `X.data`, calls to `X.step()` will ignore the random generation and\n",
    " proceed to generating points via Bayesian optimization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "      x         f  xopt_runtime  xopt_error\n1  3.00 -1.021664      0.000017       False\n2  1.75  0.312362      0.000004       False\n3  2.00 -0.272011      0.000003       False",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>f</th>\n      <th>xopt_runtime</th>\n      <th>xopt_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>3.00</td>\n      <td>-1.021664</td>\n      <td>0.000017</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.75</td>\n      <td>0.312362</td>\n      <td>0.000004</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.00</td>\n      <td>-0.272011</td>\n      <td>0.000003</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X.evaluate_data(pd.DataFrame({\"x\":[3.0, 1.75, 2.0]}))\n",
    "\n",
    "# inspect the gathered data\n",
    "X.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OptimizationOptions' object has no attribute 'turbo_state'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      3\u001B[0m generator\u001B[38;5;241m.\u001B[39mtrain_model()\n\u001B[1;32m----> 4\u001B[0m \u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_trust_region\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbounds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Xopt\\xopt\\generators\\bayesian\\bayesian_generator.py:272\u001B[0m, in \u001B[0;36mBayesianGenerator.get_trust_region\u001B[1;34m(self, bounds)\u001B[0m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    268\u001B[0m     y_last \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\n\u001B[0;32m    269\u001B[0m         objective_data\u001B[38;5;241m.\u001B[39miloc[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mto_numpy(), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tkwargs\n\u001B[0;32m    270\u001B[0m     )\n\u001B[0;32m    271\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimization_options\u001B[38;5;241m.\u001B[39mturbo_state \u001B[38;5;241m=\u001B[39m update_state(\n\u001B[1;32m--> 272\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimization_options\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mturbo_state\u001B[49m, y_last\n\u001B[0;32m    273\u001B[0m )\n\u001B[0;32m    275\u001B[0m \u001B[38;5;66;03m# calculate trust region and apply to base bounds\u001B[39;00m\n\u001B[0;32m    276\u001B[0m trust_region \u001B[38;5;241m=\u001B[39m get_trust_region(\n\u001B[0;32m    277\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocs,\n\u001B[0;32m    278\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    282\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tkwargs,\n\u001B[0;32m    283\u001B[0m )\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'OptimizationOptions' object has no attribute 'turbo_state'"
     ]
    }
   ],
   "source": [
    "# determine trust region from gathered data\n",
    "import torch\n",
    "generator.train_model()\n",
    "generator.get_trust_region(torch.tensor(vocs.bounds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Do bayesian optimization steps\n",
    "Notice that when the number of successive successes or failures reaches 2 the trust\n",
    "region expands or contracts and counters are reset to zero. Counters are also reset\n",
    "to zero during alternate successes/failures. Finally, the model is most accurate\n",
    "inside the trust region, which supports our goal of local optimization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# test points for plotting\n",
    "test_x = torch.linspace(*X.vocs.bounds.flatten(),500).double()\n",
    "\n",
    "for i in range(15):\n",
    "    # get the Gaussian process model from the generator\n",
    "    model = X.generator.train_model()\n",
    "\n",
    "    # get trust region\n",
    "    trust_region = generator.get_trust_region(torch.tensor(vocs.bounds)).squeeze()\n",
    "    scale_factor = generator.turbo_state.length\n",
    "    region_width = trust_region[1] - trust_region[0]\n",
    "    best_value = generator.turbo_state.best_value\n",
    "\n",
    "    # get number of successes and failures\n",
    "    n_successes = generator.turbo_state.success_counter\n",
    "    n_failures = generator.turbo_state.failure_counter\n",
    "\n",
    "    # get acquisition function from generator\n",
    "    acq = X.generator.get_acquisition(model)\n",
    "\n",
    "    # calculate model posterior and acquisition function at each test point\n",
    "    # NOTE: need to add a dimension to the input tensor for evaluating the\n",
    "    # posterior and another for the acquisition function, see\n",
    "    # https://botorch.org/docs/batching for details\n",
    "    # NOTE: we use the `torch.no_grad()` environment to speed up computation by\n",
    "    # skipping calculations for backpropagation\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(test_x.unsqueeze(1))\n",
    "        acq_val = acq(test_x.reshape(-1,1,1))\n",
    "\n",
    "    # get mean function and confidence regions\n",
    "    mean = posterior.mean\n",
    "    l,u = posterior.mvn.confidence_region()\n",
    "\n",
    "    # plot model and acquisition function\n",
    "    fig,ax = plt.subplots(2,1,sharex=\"all\")\n",
    "\n",
    "    # add title for successes and failures\n",
    "    ax[0].set_title(f\"n_successes: {n_successes}, n_failures: {n_failures}, \"\n",
    "                    f\"scale_factor: {scale_factor}, region_width: {region_width:.2}, \"\n",
    "                    f\"best_value: {best_value:.4}\")\n",
    "\n",
    "    # plot model posterior\n",
    "    ax[0].plot(test_x, mean, label=\"Posterior mean\")\n",
    "    ax[0].fill_between(test_x, l, u,alpha=0.25, label=\"Posterior confidence region\")\n",
    "\n",
    "    # add data to model plot\n",
    "    ax[0].plot(X.data[\"x\"],X.data[\"f\"],\"C1o\", label=\"Training data\")\n",
    "\n",
    "    # plot true function\n",
    "    true_f = sin_function({\"x\": test_x})[\"f\"]\n",
    "    ax[0].plot(test_x, true_f,'--', label=\"Ground truth\")\n",
    "\n",
    "    # add legend\n",
    "    ax[0].legend()\n",
    "\n",
    "    # plot acquisition function\n",
    "    ax[1].plot(test_x, acq_val.flatten())\n",
    "\n",
    "    ax[0].set_ylabel(\"f\")\n",
    "    ax[1].set_ylabel(r\"$\\alpha(x)$\")\n",
    "    ax[1].set_xlabel(\"x\")\n",
    "\n",
    "    # plot trust region\n",
    "    for a in ax:\n",
    "        a.axvline(trust_region[0],c=\"r\")\n",
    "        a.axvline(trust_region[1],c=\"r\")\n",
    "\n",
    "    # do the optimization step\n",
    "    X.step()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# access the collected data\n",
    "generator.get_trust_region(torch.tensor(vocs.bounds))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
